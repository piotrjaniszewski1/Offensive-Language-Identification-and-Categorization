{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ernie / Ernie.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/piotrjaniszewski1/Offensive-Language-Identification-and-Categorization/blob/ernie/Ernie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7frLgMWBG-z",
        "colab_type": "code",
        "outputId": "3c06f1a7-ff10-4b9c-dbf6-cc763108a501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Install necessary packages -> uncomment what is currently needed\n",
        "\n",
        "!pip install unidecode\n",
        "!pip install contractions\n",
        "!pip install wordsegment\n",
        "!pip install -U symspellpy\n",
        "!pip install emoji --upgrade\n",
        "!pip install -U imbalanced-learn\n",
        "!pip install bert-for-tf2\n",
        "!pip install transformers\n",
        "!pip install paddlepaddle-gpu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: contractions in /usr/local/lib/python3.6/dist-packages (0.0.24)\n",
            "Requirement already satisfied: textsearch in /usr/local/lib/python3.6/dist-packages (from contractions) (0.0.17)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.4.0)\n",
            "Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.1.1)\n",
            "Requirement already satisfied: wordsegment in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already up-to-date: symspellpy in /usr/local/lib/python3.6/dist-packages (6.5.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from symspellpy) (1.17.4)\n",
            "Requirement already up-to-date: emoji in /usr/local/lib/python3.6/dist-packages (0.5.4)\n",
            "Requirement already up-to-date: imbalanced-learn in /usr/local/lib/python3.6/dist-packages (0.6.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.22 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.22)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.3.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.17.4)\n",
            "Requirement already satisfied: bert-for-tf2 in /usr/local/lib/python3.6/dist-packages (0.12.6)\n",
            "Requirement already satisfied: params-flow>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from bert-for-tf2) (0.7.4)\n",
            "Requirement already satisfied: py-params>=0.7.3 in /usr/local/lib/python3.6/dist-packages (from bert-for-tf2) (0.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.7.1->bert-for-tf2) (1.17.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.7.1->bert-for-tf2) (4.28.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.35)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.9)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.40)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.40 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.40)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.40->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.40->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: paddlepaddle-gpu in /usr/local/lib/python3.6/dist-packages (1.6.2.post107)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (0.7.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (4.3.0)\n",
            "Requirement already satisfied: scipy; python_version >= \"3.5\" in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (1.3.3)\n",
            "Requirement already satisfied: objgraph in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (3.4.1)\n",
            "Requirement already satisfied: nltk; python_version >= \"3.5\" in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (3.2.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (4.1.2.30)\n",
            "Requirement already satisfied: funcsigs in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (1.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (3.13)\n",
            "Requirement already satisfied: rarfile in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (3.1)\n",
            "Requirement already satisfied: matplotlib; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (3.1.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (4.4.1)\n",
            "Requirement already satisfied: numpy>=1.12; python_version >= \"3.5\" in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (1.17.4)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (0.10.1)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (2.21.0)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (3.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->paddlepaddle-gpu) (0.46)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu) (2.4.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu) (2.6.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->paddlepaddle-gpu) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->paddlepaddle-gpu) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->paddlepaddle-gpu) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->paddlepaddle-gpu) (2.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.1.0->paddlepaddle-gpu) (42.0.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Yk1KF2QClpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# All imports - DO NOT CHANGE THE ORDER OF INSTRUCTIONS\n",
        "#!test -d bert_repo || git clone https://github.com/google-research/bert bert_repo\n",
        "\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "\n",
        "#if not 'bert_repo' in sys.path:\n",
        "    #sys.path.insert(0, 'bert_repo')\n",
        "\n",
        "import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "import spacy\n",
        "from bs4 import BeautifulSoup\n",
        "import unidecode\n",
        "import contractions\n",
        "import gensim.downloader as api\n",
        "import re\n",
        "import wordsegment\n",
        "import pkg_resources\n",
        "from symspellpy.symspellpy import SymSpell, Verbosity\n",
        "import emoji\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "#from modeling import BertModel, BertConfig\n",
        "#from tokenization import FullTokenizer, convert_to_unicode\n",
        "#from extract_features import InputExample, convert_examples_to_features\n",
        "from tqdm import tqdm\n",
        "#import tensorflow_addons as tfa\n",
        "# import nltk\n",
        "from google.colab import auth, drive\n",
        "# nltk.download('punkt')\n",
        "\n",
        "wordsegment.load()\n",
        "\n",
        "# Load SymSpell -> package for correcting misspellings\n",
        "sym_spell = SymSpell(2, 7)\n",
        "\n",
        "dictionary_path = pkg_resources.resource_filename(\n",
        "    \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
        "bigram_path = pkg_resources.resource_filename(\n",
        "    \"symspellpy\", \"frequency_bigramdictionary_en_243_342.txt\")\n",
        "\n",
        "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
        "sym_spell.load_bigram_dictionary(bigram_path, term_index=0, count_index=2)\n",
        "\n",
        "# get TF logger \n",
        "log = logging.getLogger('tensorflow')\n",
        "log.handlers = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-2A9THPfViR",
        "colab_type": "code",
        "outputId": "54720d9e-0458-4995-ca92-13d4b388cc41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#Import data\n",
        "training_examples_url = 'https://raw.githubusercontent.com/piotrjaniszewski1/SemEval-2020-Task12/master/data2019/olid-training-v1.0.tsv'\n",
        "training_dataset = pd.read_csv(training_examples_url, delimiter='\\t')\n",
        "print(training_dataset.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      id                                              tweet  ... subtask_b subtask_c\n",
            "0  86426  @USER She should ask a few native Americans wh...  ...       UNT       NaN\n",
            "1  90194  @USER @USER Go home youâ€™re drunk!!! @USER #MAG...  ...       TIN       IND\n",
            "2  16820  Amazon is investigating Chinese employees who ...  ...       NaN       NaN\n",
            "3  62688  @USER Someone should'veTaken\" this piece of sh...  ...       UNT       NaN\n",
            "4  43605  @USER @USER Obama wanted liberals &amp; illega...  ...       NaN       NaN\n",
            "\n",
            "[5 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrWT8auffaHx",
        "colab_type": "text"
      },
      "source": [
        "# **Training and validation sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoLqOPNzfXsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_examples, validation_examples = train_test_split(training_dataset, test_size=0.1)\n",
        "\n",
        "# prepare training examples\n",
        "training_examples_A = training_examples['tweet'][training_examples['subtask_a'].notnull()]\n",
        "training_examples_B = training_examples['tweet'][training_examples['subtask_b'].notnull()]\n",
        "training_examples_C = training_examples['tweet'][training_examples['subtask_c'].notnull()]\n",
        "\n",
        "# prepare validation examples\n",
        "validation_examples_A = validation_examples['tweet'][validation_examples['subtask_a'].notnull()]\n",
        "validation_examples_B = validation_examples['tweet'][validation_examples['subtask_b'].notnull()]\n",
        "validation_examples_C = validation_examples['tweet'][validation_examples['subtask_c'].notnull()]\n",
        "\n",
        "# prepare training labels\n",
        "training_labels_A = np.array((training_examples['subtask_a'][training_examples['subtask_a'].notnull()] == 'OFF').astype(int))\n",
        "training_labels_B = np.array((training_examples['subtask_b'][training_examples['subtask_b'].notnull()] == 'TIN').astype(int))\n",
        "c_mapping = {'IND': 0, 'GRP': 1, 'OTH': 2}\n",
        "training_labels_C = np.array(training_examples['subtask_c'][training_examples['subtask_c'].notnull()].replace(c_mapping))\n",
        "\n",
        "# prepare validation labels\n",
        "validation_labels_A = (validation_examples['subtask_a'][validation_examples['subtask_a'].notnull()] == 'OFF').astype(int)\n",
        "validation_labels_B = (validation_examples['subtask_b'][validation_examples['subtask_b'].notnull()] == 'TIN').astype(int)\n",
        "validation_labels_C = (validation_examples['subtask_c'][validation_examples['subtask_c'].notnull()]).replace(c_mapping)\n",
        "\n",
        "\n",
        "training_x = np.array(training_examples_A)\n",
        "validation_x = np.array(validation_examples_A)\n",
        "training_y = np.array(training_labels_A)\n",
        "validation_y = np.array(validation_labels_A)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIx5-CLpffCo",
        "colab_type": "text"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Slqijwp6fqEy",
        "colab_type": "text"
      },
      "source": [
        "### Common preprocessing functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0TyndvDfds1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove html tags if exist\n",
        "def strip_html_tags(text):\n",
        "    soup = BeautifulSoup(text, 'html.parser')\n",
        "    stripped_text = soup.get_text(separator=' ')\n",
        "    return stripped_text\n",
        "\n",
        "\n",
        "# remove unnecessary whitespaces\n",
        "def remove_whitespace(text):\n",
        "    text = text.strip()\n",
        "    return ' '.join(text.split())\n",
        "\n",
        "\n",
        "# remove accented chars (e.g. caffÃ¨ -> caffe)\n",
        "def remove_accented_chars(text):\n",
        "    text = unidecode.unidecode(text)\n",
        "    return text\n",
        "\n",
        "\n",
        "# remove hashes and split words (e.g. '#fortTrump' -> 'fort trump')\n",
        "def split_hashtags(text):\n",
        "    splitted = text.split()\n",
        "    new_word_sequence = []\n",
        "\n",
        "    for chunk in splitted:\n",
        "        if chunk[0] == '#':\n",
        "            chunk = chunk[1:]\n",
        "            new_word_sequence.extend(wordsegment.segment(chunk))\n",
        "        else:\n",
        "            new_word_sequence.append(chunk)\n",
        "        \n",
        "    return ' '.join(tuple(new_word_sequence))\n",
        "\n",
        "\n",
        "def substitute_emojis(text):\n",
        "    demojized_text = emoji.demojize(text)\n",
        "    return re.compile('[_:]+').sub(' ', demojized_text)\n",
        "\n",
        "\n",
        "def preprocess_common(text):\n",
        "    text = strip_html_tags(text)\n",
        "    text = contractions.fix(text)\n",
        "    text = split_hashtags(text)\n",
        "    text = substitute_emojis(text)\n",
        "    text = remove_whitespace(text)\n",
        "    text = remove_accented_chars(text)\n",
        "    return text.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF7yd2-ofsPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove redundant @user tokens\n",
        "def remove_redundant_users(example):\n",
        "    user_count = 0\n",
        "    new_example = example[:]\n",
        "    for i, token in reversed(list(enumerate(example))):\n",
        "        if token == '@user':\n",
        "            user_count += 1\n",
        "        if user_count > 3:\n",
        "            new_example.pop(i)\n",
        "    else:\n",
        "        user_count = 0\n",
        "\n",
        "    return new_example"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha_QGMCegBNp",
        "colab_type": "text"
      },
      "source": [
        "### Spacy preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcKKJJvwfuFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Try leaving '?' and '!' as far as punctuation is concerned\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# exclude negation words from spacy stopwords list\n",
        "deselect_stop_words = ['no', 'not', 'noone', 'none', 'lacks', 'lack', 'nor', 'never', 'neighter', 'hardly', 'nobody', 'nothing', 'lacking', 'nowhere']\n",
        "for w in deselect_stop_words:\n",
        "    nlp.vocab[w].is_stop = False\n",
        "\n",
        "def preprocess_spacy(text):\n",
        "    doc = nlp(text)\n",
        "\n",
        "    clean_text = []\n",
        "    \n",
        "    for token in doc:\n",
        "        flag = True\n",
        "        edit = token.text\n",
        "\n",
        "        # remove punctuations\n",
        "        if token.pos_ == 'PUNCT' and flag == True and token.text != '@user': \n",
        "            flag = False\n",
        "       \n",
        "        # remove special characters\n",
        "        if token.pos_ == 'SYM' and flag == True: \n",
        "            flag = False\n",
        "        \n",
        "        # remove numbers\n",
        "        if (token.pos_ == 'NUM' or token.text.isnumeric()) and flag == True:\n",
        "            flag = False\n",
        "\n",
        "        # correct misspelings\n",
        "        if flag == True:\n",
        "            suggestions = sym_spell.lookup(edit, Verbosity.TOP, 2)\n",
        "            if len(suggestions) > 0:\n",
        "                edit = suggestions[0].term\n",
        "\n",
        "        # remove stop words\n",
        "        if token.is_stop and token.pos_ != 'NUM': \n",
        "            flag = False\n",
        "\n",
        "        # convert tokens to base form\n",
        "        elif token.lemma_ != '-PRON-' and flag == True:\n",
        "            edit = token.lemma_\n",
        "\n",
        "        # append tokens edited and not removed to list \n",
        "        if edit != '' and flag == True:\n",
        "            clean_text.append(edit)        \n",
        "    \n",
        "    return clean_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I1NZ62HgDph",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YAsJrM-gFvd",
        "colab_type": "code",
        "outputId": "3462a2a5-2832-46e1-d00d-95b10742c227",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "# normalization -> papers, complicated solutions, replace abbreviations with full names (e.g. MAGA)\n",
        "# check removing less stop words (some may have some significance)\n",
        "\n",
        "cleaned_x = [preprocess_spacy(example) for example in training_x[0:30]]\n",
        "reduced_users_x = [remove_redundant_users(example) for example in cleaned_x]\n",
        "print(reduced_users_x[0:30])\n",
        "print(training_x[0:30])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Verge', 'collapse)the', 'breaking', 'wave', 'not', 'explain', 'sea.', 'ðŸ¤”', 'fast', 'break', 'thing', 'tell', 'break', 'â€¦', 'url'], ['@USER', 'Loll'], ['@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', 'follow', 'patriot', 'follow', 'thank', 'maga', 'KAG', 'WalkAway', 'Witchhunt', '#', 'redwaverise', 'VoteRed', '#', 'VoteDemsOut', 'voteredtosaveamerica'], ['@USER', 'ANTIFA', 'WANNABE', 'â˜', 'â˜', 'â˜', 'â˜'], ['@USER', '@USER', 'different', 'opinion', 'well', 'gun', 'control', 'law', 'look', 'like', 'ðŸ˜Ž', ' ', 'case', 'illegal', 'alien', 'right', 'involve', ' ', 'case', 'Americans', '2a', 'right', ' ', 'u', 'tell', 'difference', 'american', 'right', '&', 'amp', 'illegal', 'alien'], ['@USER', 'happy', 'birthday', 'sweetie', 'hope', 'day', 'awesome'], ['@user', 'devil', 'single', 'priest', 'rape', 'child', 'pope', 'refuse', 'condemn', 'remove', 'leadership', 'rapist', 'bring'], ['@USER', '@USER', 'McKenna', 'no', 'longer', 'Twitter', 'defect', 'Conservatives'], ['people', 'shoot', 'kill', 'Bakersfield', 'liberal', 'want', 'tweet', 'Gun', 'Control', ' ', 'Chicago', 'call', 'people', 'shoot', 'kill', 'lunch', 'break', 'nobody', 'tweet', 'word', ' ', 'not', 'way', ' ', 'legal', 'gun', 'ownership', 'vs', 'illegal', 'gun', 'ownership', 'â€™s', 'real', 'solution'], ['@USER', 'dissapointe', 'guy', 'big', 'hypocrite', 'country', 'embarrass', 'Senator'], ['@USER', 'hit', 'lotto'], ['@USER', '@USER', 'Lambda', 'low', 'end', 'say', 'high', 'end', 'try', 'influence', ' ', 'right', 'well', 'investment', 'exclusively', 'return', 'PoV', 'quality', 'life', 'return', 'PoV', 'money', 'not'], ['@USER', '@USER', 'oh', '@USER', 'dem', 'candidate', 'clearly', 'state', 'policy', 'proposal', 'involve', 'rational', 'gun', 'control', 'elect', 'will', 'not', 'vacillate', 'like', 'Trump', '@USER', 'deceive', 'America'], ['@USER', '@USER', '@USER', 'House', 'price', 'increase', 'nothing', 'immigration', 'lack', 'affordable', 'housing', 'mainly', 'government', 'not', 'build', 'inflated', 'price', 'bank', 'lending', 'practice', ' ', 'url'], ['@USER', 'Antifa', 'simply', 'want', 'kill', 'way', 'carry', 'knife'], ['@USER', '@USER', 'explain', 'anti', 'gun', 'control', 'desantis', 'hold', 'people', 'accountable'], ['@USER', '@USER', 'FIRED', 'dead', 'public', 'fake', 'NEWS', 'approach', 'crowd', 'scared', 'stand', 'fire', 'Kitchen'], ['@USER', 'happiness', 'hold', 'not', 'cause', 'pass', 'overdose', 'destruction', 'not', 'blame', 'no', 'plus', 'be', 'pretty', 'sure', 'mess', 'death'], ['@USER', '@USER', '@USER', 'fuck', 'detect', 'attitude', 'text', 'bubble'], ['@user', 'â€™s', 'funny', 'idiot', 'liberal', 'forget', 'president', 'shit', 'Haha'], ['@USER', '@USER', 'shall', 'know', 'way', 'bear'], ['@USER', 'send', '@USER', ' ', 'way', 'dinner', 'say', 'meet', 'tonight', 'not', 'tell', 'Clemson', 'legend', 'like', 'Aggie', 'yell', 'leader', 'legend', 'cheer', 'Clemson', 'espn', 'commentator', 'Varsity'], ['voterepublican', 'ï¸#arm', 'â™¨', 'ï¸#americanredmidterm', ' ', 'let', 'Democrats', 'tax', 'cut', 'reform', 'money', 'pocket', '  ', '#', 'conservative', '#', 'Independents', 'undecided', '#', 'WalkAway', '#', 'ljmaga', ' ', '#', 'goredstatebystate', 'url'], ['@USER', 'support', 'antifa'], ['@USER', '@USER', 'Gun', 'control', ' ', 'good', 'example', 'bad', 'idea', 'cop', 'one', 'gun', ' ', 'have', 'gun', 'close', 'thing', 'save', 'poor', 'man'], ['@USER', '@USER', 'yes', 'READ', 'use', 'term', 'BROAD', 'group', 'leftist', 'feminist', 'theist', 'case', 'focus', 'particular', 'EXTREME', 'SUBSET', 'group', 'antifa', 'subset', '3rd', 'wave', 'feminism', 'YECs', 'distinguish', 'fact', 'subset'], ['@USER', '@USER', '@USER', 'people', 'bastard', 'hopelessly', 'naÃ¯ve', 'think', 'plenty', 'fraud', 'will', 'advantage', 'law', 'change', 'malign', 'purpose'], ['@USER', 'Hey', 'Serena', 'donâ€™t', 'favor', ' ', 'Women', 'care', ' ', 'hit', 'tennis', 'ball', 'care', 'family'], ['@USER', '@USER', 'ðŸ˜‚', 'ðŸ˜‚', 'ðŸ˜‚', 'ðŸ˜‚', 'thank', 'history', 'lesson', 'excuse', 'talk', 'past', 'game', 'today', 'better', 'good', 'game'], ['@user', 'little', 'pussy', 'say', 'SHIT', 'people']]\n",
            "['(Verge of collapse)The breaking of a wave cannot explain the whole sea.ðŸ¤”I move too fast and break things. But i have always told myself Unless you are breakingâ€¦ URL'\n",
            " '@USER Loll he is!'\n",
            " '@USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER Following all patriots. PLEASE follow back. Thank you. #MAGA #KAG #WalkAway #Witchhunt #RedWaveRising #VoteRed #VoteDemsOut #VoteRedToSaveAmerica'\n",
            " '@USER ANTIFA WANNABE â˜â˜â˜â˜'\n",
            " '@USER @USER We have a different opinion of what a better\" gun control law looks like.ðŸ˜Ž  In one case an illegal alien with NO RIGHT to be here is involved.  In the other case Americans have 2A rights.  Can u tell the difference between American rights &amp; illegal aliens?\"'\n",
            " '@USER Happy birthday sweetie!!! Hope your day is as awesome as you are!!!'\n",
            " \"@USER Even if the devil did make every single one of those priests rape children... Why does the pope refuse to condemn it? Why didn't he remove from leadership the rapist brought to him?\"\n",
            " \"@USER @USER where's McKenna? She no longer using Twitter. Did she defect to the Conservatives?\"\n",
            " '6 people shot and killed in Bakersfield and the liberals want to tweet about Gun Control.  Chicago calls 6 people shot and killed a lunch break yet nobody tweets a word.  You canâ€™t have it both ways.  Legal guns ownership vs illegal gun ownership. Whatâ€™s the real solution?'\n",
            " '@USER So Dissapointing. This guy is the biggest hypocrite in the country. Embarrassing that he is our Senator'\n",
            " '@USER He hit the lotto'\n",
            " '@USER @USER And Lambda would be on the lower end, as others are saying on the high end is trying for influence.  Anyway, you are right in that I wasn\\'t using better investment\" exclusively from a $ return PoV, but from a \"quality of life return\" PoV... some of that is money but not all.\"'\n",
            " '@USER @USER Oh @USER The Dem candidates do have clearly stated policy proposals. One involves rational gun control. When elected they wonâ€™t vacillate like Trump. You and @USER are done deceiving America.'\n",
            " '@USER @USER @USER House price increase has nothing to do with immigration. The lack of affordable housing is mainly down to this government not building any and the inflated prices are down to the banks and their lending practices.  URL'\n",
            " '@USER Antifa simply wants us to kill them. By the way. Most of us carry a back up. And a knife'\n",
            " '@USER @USER Please explain why anti any gun control desantis would somehow hold people accountable?'\n",
            " \"@USER @USER YOU should be FIRED... You are dead to the public for your FAKE NEWS Why don't you show him approaching the crowd? Scared ... If you can't stand the fire Get Out of the Kitchen....\"\n",
            " '@USER so she was to put her happiness on hold for him to get himself together. she is not the cause of his passing he overdosed. if anything he was his own destruction. you canâ€™t put the blame on her no one can. plus Iâ€™m pretty sure she is just a messed up about his death as anyone.'\n",
            " '@USER @USER @USER How the fuck can he detect an attitude through a text bubble?'\n",
            " '@USER Itâ€™s funny how you idiot liberals seem to forget when other presidents do the same shit. Haha.'\n",
            " '@USER @USER He shall know your ways as if born to them.'\n",
            " '. @USER i sent @USER  your way for dinner. She said she met you tonight but What she didnâ€™t tell you is that she is Clemson legend like you are an Aggie yell leader legend. She cheered at Clemson and is a ESPN commentator for Varsity!'\n",
            " \"#VoteRepublicanâ™¨ï¸#ARMâ™¨ï¸#AmericanRedMidterms  We can't let the Democrats take back the tax cuts and the reforms that have put more money in so many pockets.   #Conservatives #Independents #Undecided #WalkAway #LJMAGA  #GoRedStateByState URL\"\n",
            " '@USER Also he supports antifa'\n",
            " \"@USER @USER Gun control?  This is a really good example why it's a bad idea for cops to be the only ones with guns.  Having a gun really close is the only thing that might have saved this poor man.\"\n",
            " '@USER @USER Yes, READ it again. They use a term for a BROAD group (leftist\" \"feminist\" \"theist\" whatever else) then, in many cases, focus on a particular EXTREME SUBSET of that group (antifa, a subset of 3rd wave feminism, YECs) without distinguishing the fact it IS a subset.\"'\n",
            " \"@USER @USER @USER Because some people are bastards. You're hopelessly naÃ¯ve if you think plenty of frauds won't take advantage of this law change for malign purposes.\"\n",
            " '@USER Hey Serena...donâ€™t do me any favors.  Women can take care of themselves.  Just hit your tennis balls and take care of your family.'\n",
            " '@USER @USER ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ thanks for the history lesson. Excuses and talking about past games make today even better. You are only as good as your last game...'\n",
            " \"@USER WHAT I SAY ABOUT BEING A LITTLE PUSSY AND SAYING SHIT BEHIND PEOPLE'S BACK\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWkFh8tJjeyP",
        "colab_type": "text"
      },
      "source": [
        "# **Save data to file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXcp_1yTjcEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.DataFrame(training_x, columns = ['text_a'])\n",
        "train['label'] = training_y\n",
        "val = pd.DataFrame(validation_x, columns = ['text_a'])\n",
        "val['label'] = validation_y\n",
        "train.to_csv('train.tsv', index=False, sep='\\t')\n",
        "val.to_csv('val.tsv', index=False, sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96_du6DZpQJs",
        "colab_type": "text"
      },
      "source": [
        "# Download model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XSNataMlwKX",
        "colab_type": "code",
        "outputId": "c3dbfd30-870c-4e23-94da-925bf3d1d4e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/PaddlePaddle/ERNIE.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ERNIE'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 1253 (delta 13), reused 20 (delta 6), pack-reused 1218\u001b[K\n",
            "Receiving objects: 100% (1253/1253), 15.70 MiB | 13.71 MiB/s, done.\n",
            "Resolving deltas: 100% (702/702), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eo0e8FUpPHs",
        "colab_type": "code",
        "outputId": "87599454-a2e2-4d27-ed0f-72fe8668f6b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!wget https://ernie.bj.bcebos.com/ERNIE_Base_en_stable-2.0.0.tar.gz\n",
        "!gunzip ERNIE_Base_en_stable-2.0.0.tar.gz\n",
        "!tar -xvf ERNIE_Base_en_stable-2.0.0.tar"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-29 21:15:53--  https://ernie.bj.bcebos.com/ERNIE_Base_en_stable-2.0.0.tar.gz\n",
            "Resolving ernie.bj.bcebos.com (ernie.bj.bcebos.com)... 103.235.46.61\n",
            "Connecting to ernie.bj.bcebos.com (ernie.bj.bcebos.com)|103.235.46.61|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 405413980 (387M) [application/x-gzip]\n",
            "Saving to: â€˜ERNIE_Base_en_stable-2.0.0.tar.gzâ€™\n",
            "\n",
            "ERNIE_Base_en_stabl 100%[===================>] 386.63M  6.79MB/s    in 2m 41s  \n",
            "\n",
            "2019-12-29 21:18:38 (2.40 MB/s) - â€˜ERNIE_Base_en_stable-2.0.0.tar.gzâ€™ saved [405413980/405413980]\n",
            "\n",
            "ernie_config.json\n",
            "params/\n",
            "params/encoder_layer_4_post_att_layer_norm_scale\n",
            "params/encoder_layer_2_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_2_ffn_fc_1.w_0\n",
            "params/encoder_layer_6_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_7_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_11_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_5_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_1_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_11_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_7_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_1_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_9_ffn_fc_1.b_0\n",
            "params/encoder_layer_4_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_2_ffn_fc_1.b_0\n",
            "params/encoder_layer_7_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_7_post_att_layer_norm_scale\n",
            "params/encoder_layer_6_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_10_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_5_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_3_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_1_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_10_ffn_fc_0.w_0\n",
            "params/encoder_layer_6_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_3_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_8_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_4_post_att_layer_norm_bias\n",
            "params/pre_encoder_layer_norm_scale\n",
            "params/encoder_layer_2_post_att_layer_norm_scale\n",
            "params/encoder_layer_5_post_att_layer_norm_bias\n",
            "params/encoder_layer_4_ffn_fc_0.b_0\n",
            "params/encoder_layer_4_ffn_fc_1.b_0\n",
            "params/encoder_layer_10_ffn_fc_1.w_0\n",
            "params/encoder_layer_2_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_3_post_att_layer_norm_bias\n",
            "params/encoder_layer_1_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_0_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_8_ffn_fc_1.b_0\n",
            "params/encoder_layer_3_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_2_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_6_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_6_post_att_layer_norm_scale\n",
            "params/encoder_layer_0_post_att_layer_norm_scale\n",
            "params/encoder_layer_2_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_5_ffn_fc_1.w_0\n",
            "params/encoder_layer_0_ffn_fc_0.b_0\n",
            "params/encoder_layer_1_post_att_layer_norm_scale\n",
            "params/encoder_layer_6_post_att_layer_norm_bias\n",
            "params/encoder_layer_4_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_5_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_11_post_att_layer_norm_scale\n",
            "params/encoder_layer_9_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_9_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_0_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_2_ffn_fc_0.w_0\n",
            "params/pos_embedding\n",
            "params/encoder_layer_8_ffn_fc_0.b_0\n",
            "params/encoder_layer_11_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_0_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_9_post_att_layer_norm_bias\n",
            "params/encoder_layer_2_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_5_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_9_multi_head_att_key_fc.b_0\n",
            "params/task_embedding\n",
            "params/encoder_layer_10_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_4_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_7_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_7_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_0_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_10_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_1_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_5_post_att_layer_norm_scale\n",
            "params/encoder_layer_8_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_0_ffn_fc_0.w_0\n",
            "params/encoder_layer_5_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_7_ffn_fc_0.w_0\n",
            "params/encoder_layer_7_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_7_ffn_fc_1.w_0\n",
            "params/encoder_layer_2_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_9_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_9_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_9_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_4_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_11_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_5_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_1_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_0_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_6_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_7_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_8_ffn_fc_1.w_0\n",
            "params/encoder_layer_9_ffn_fc_1.w_0\n",
            "params/sent_embedding\n",
            "params/encoder_layer_0_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_10_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_6_ffn_fc_0.w_0\n",
            "params/encoder_layer_1_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_5_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_6_ffn_fc_1.b_0\n",
            "params/encoder_layer_0_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_5_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_2_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_0_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_9_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_1_ffn_fc_1.w_0\n",
            "params/encoder_layer_0_ffn_fc_1.w_0\n",
            "params/encoder_layer_8_ffn_fc_0.w_0\n",
            "params/encoder_layer_11_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_5_ffn_fc_0.w_0\n",
            "params/pre_encoder_layer_norm_bias\n",
            "params/encoder_layer_6_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_10_ffn_fc_0.b_0\n",
            "params/encoder_layer_6_ffn_fc_1.w_0\n",
            "params/encoder_layer_4_ffn_fc_1.w_0\n",
            "params/encoder_layer_2_ffn_fc_0.b_0\n",
            "params/encoder_layer_5_ffn_fc_0.b_0\n",
            "params/encoder_layer_10_ffn_fc_1.b_0\n",
            "params/pooled_fc.w_0\n",
            "params/encoder_layer_7_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_8_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_3_ffn_fc_0.b_0\n",
            "params/encoder_layer_11_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_7_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_9_ffn_fc_0.w_0\n",
            "params/encoder_layer_9_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_0_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_7_post_att_layer_norm_bias\n",
            "params/encoder_layer_3_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_11_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_5_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_0_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_4_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_3_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_3_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_11_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_8_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_4_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_6_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_9_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_3_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_6_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_9_ffn_fc_0.b_0\n",
            "params/encoder_layer_10_post_att_layer_norm_scale\n",
            "params/encoder_layer_11_ffn_fc_0.b_0\n",
            "params/pooled_fc.b_0\n",
            "params/encoder_layer_2_post_att_layer_norm_bias\n",
            "params/encoder_layer_8_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_1_ffn_fc_0.w_0\n",
            "params/encoder_layer_4_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_8_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_10_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_6_ffn_fc_0.b_0\n",
            "params/encoder_layer_5_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_3_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_3_ffn_fc_1.b_0\n",
            "params/encoder_layer_10_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_10_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_8_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_8_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_11_post_att_layer_norm_bias\n",
            "params/encoder_layer_8_post_att_layer_norm_scale\n",
            "params/encoder_layer_10_post_att_layer_norm_bias\n",
            "params/encoder_layer_4_ffn_fc_0.w_0\n",
            "params/encoder_layer_1_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_4_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_11_ffn_fc_0.w_0\n",
            "params/encoder_layer_3_post_att_layer_norm_scale\n",
            "params/encoder_layer_10_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_11_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_10_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_6_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_8_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_0_ffn_fc_1.b_0\n",
            "params/encoder_layer_9_post_att_layer_norm_scale\n",
            "params/word_embedding\n",
            "params/encoder_layer_3_ffn_fc_1.w_0\n",
            "params/encoder_layer_11_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_3_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_11_ffn_fc_1.b_0\n",
            "params/encoder_layer_2_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_3_ffn_fc_0.w_0\n",
            "params/encoder_layer_5_ffn_fc_1.b_0\n",
            "params/encoder_layer_1_ffn_fc_0.b_0\n",
            "params/encoder_layer_1_ffn_fc_1.b_0\n",
            "params/encoder_layer_8_post_att_layer_norm_bias\n",
            "params/encoder_layer_7_ffn_fc_0.b_0\n",
            "params/encoder_layer_1_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_2_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_7_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_3_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_11_ffn_fc_1.w_0\n",
            "params/encoder_layer_1_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_0_post_att_layer_norm_bias\n",
            "params/encoder_layer_4_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_2_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_4_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_8_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_10_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_7_ffn_fc_1.b_0\n",
            "params/encoder_layer_1_post_att_layer_norm_bias\n",
            "params/encoder_layer_9_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_6_post_ffn_layer_norm_bias\n",
            "vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvYrn4PUpwOQ",
        "colab_type": "code",
        "outputId": "55173d36-89c7-4509-89e6-a6e98de46c6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!mkdir -p parameters/params\n",
        "!mkdir -p 'dataset/sem-eval'\n",
        "!mv train.tsv dataset/sem-eval/\n",
        "!mv val.tsv dataset/sem-eval/\n",
        "!mv params/ parameters/params"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot move 'params/' to 'parameters/params/params': Directory not empty\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8m9ZA3sp4GH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv dataset/ ERNIE/\n",
        "!mv parameters/ ERNIE/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI9CIul0nKj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('ERNIE/')\n",
        "os.environ['TASK_DATA_PATH']='dataset'\n",
        "os.environ['MODEL_PATH']='parameters/params'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeF7dJZvs2cT",
        "colab_type": "text"
      },
      "source": [
        "# Run classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL2SoNJlnNMt",
        "colab_type": "code",
        "outputId": "b5e5bd6b-9e1d-4419-e6a2-c3448d934708",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNZ7B3gJs9IH",
        "colab_type": "code",
        "outputId": "716832f0-3452-4c25-9e36-bd1ce9444b7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!sh '/content/gdrive/My Drive/Pracownia/Ernie/sem-eval-task.sh'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Pracownia/Ernie/sem-eval-task.sh: 8: /content/gdrive/My Drive/Pracownia/Ernie/sem-eval-task.sh: [[: not found\n",
            "2019-12-29 21:26:05,220-INFO: -----------  Configuration Arguments -----------\n",
            "[INFO] 2019-12-29 21:26:05,220 [     args.py:   68]:\t-----------  Configuration Arguments -----------\n",
            "2019-12-29 21:26:05,220-INFO: batch_size: 32\n",
            "[INFO] 2019-12-29 21:26:05,220 [     args.py:   70]:\tbatch_size: 32\n",
            "2019-12-29 21:26:05,220-INFO: checkpoints: ./checkpoints\n",
            "[INFO] 2019-12-29 21:26:05,220 [     args.py:   70]:\tcheckpoints: ./checkpoints\n",
            "2019-12-29 21:26:05,220-INFO: chunk_scheme: IOB\n",
            "[INFO] 2019-12-29 21:26:05,220 [     args.py:   70]:\tchunk_scheme: IOB\n",
            "2019-12-29 21:26:05,220-INFO: decr_every_n_nan_or_inf: 2\n",
            "[INFO] 2019-12-29 21:26:05,220 [     args.py:   70]:\tdecr_every_n_nan_or_inf: 2\n",
            "2019-12-29 21:26:05,220-INFO: decr_ratio: 0.8\n",
            "[INFO] 2019-12-29 21:26:05,220 [     args.py:   70]:\tdecr_ratio: 0.8\n",
            "2019-12-29 21:26:05,220-INFO: dev_set: None\n",
            "[INFO] 2019-12-29 21:26:05,220 [     args.py:   70]:\tdev_set: None\n",
            "2019-12-29 21:26:05,220-INFO: diagnostic: None\n",
            "[INFO] 2019-12-29 21:26:05,220 [     args.py:   70]:\tdiagnostic: None\n",
            "2019-12-29 21:26:05,220-INFO: diagnostic_save: None\n",
            "[INFO] 2019-12-29 21:26:05,220 [     args.py:   70]:\tdiagnostic_save: None\n",
            "2019-12-29 21:26:05,220-INFO: do_lower_case: True\n",
            "[INFO] 2019-12-29 21:26:05,220 [     args.py:   70]:\tdo_lower_case: True\n",
            "2019-12-29 21:26:05,220-INFO: do_test: True\n",
            "[INFO] 2019-12-29 21:26:05,220 [     args.py:   70]:\tdo_test: True\n",
            "2019-12-29 21:26:05,220-INFO: do_train: True\n",
            "[INFO] 2019-12-29 21:26:05,220 [     args.py:   70]:\tdo_train: True\n",
            "2019-12-29 21:26:05,221-INFO: do_val: False\n",
            "[INFO] 2019-12-29 21:26:05,221 [     args.py:   70]:\tdo_val: False\n",
            "2019-12-29 21:26:05,221-INFO: doc_stride: 128\n",
            "[INFO] 2019-12-29 21:26:05,221 [     args.py:   70]:\tdoc_stride: 128\n",
            "2019-12-29 21:26:05,221-INFO: enable_ce: False\n",
            "[INFO] 2019-12-29 21:26:05,221 [     args.py:   70]:\tenable_ce: False\n",
            "2019-12-29 21:26:05,221-INFO: epoch: 4\n",
            "[INFO] 2019-12-29 21:26:05,221 [     args.py:   70]:\tepoch: 4\n",
            "2019-12-29 21:26:05,221-INFO: ernie_config_path: script/en_glue/ernie_base/ernie_config.json\n",
            "[INFO] 2019-12-29 21:26:05,221 [     args.py:   70]:\ternie_config_path: script/en_glue/ernie_base/ernie_config.json\n",
            "2019-12-29 21:26:05,221-INFO: for_cn: False\n",
            "[INFO] 2019-12-29 21:26:05,221 [     args.py:   70]:\tfor_cn: False\n",
            "2019-12-29 21:26:05,221-INFO: in_tokens: False\n",
            "[INFO] 2019-12-29 21:26:05,221 [     args.py:   70]:\tin_tokens: False\n",
            "2019-12-29 21:26:05,221-INFO: incr_every_n_steps: 100\n",
            "[INFO] 2019-12-29 21:26:05,221 [     args.py:   70]:\tincr_every_n_steps: 100\n",
            "2019-12-29 21:26:05,221-INFO: incr_ratio: 2.0\n",
            "[INFO] 2019-12-29 21:26:05,221 [     args.py:   70]:\tincr_ratio: 2.0\n",
            "2019-12-29 21:26:05,221-INFO: init_checkpoint: None\n",
            "[INFO] 2019-12-29 21:26:05,221 [     args.py:   70]:\tinit_checkpoint: None\n",
            "2019-12-29 21:26:05,221-INFO: init_loss_scaling: 102400\n",
            "[INFO] 2019-12-29 21:26:05,221 [     args.py:   70]:\tinit_loss_scaling: 102400\n",
            "2019-12-29 21:26:05,221-INFO: init_pretraining_params: parameters/params/params\n",
            "[INFO] 2019-12-29 21:26:05,221 [     args.py:   70]:\tinit_pretraining_params: parameters/params/params\n",
            "2019-12-29 21:26:05,221-INFO: is_classify: True\n",
            "[INFO] 2019-12-29 21:26:05,221 [     args.py:   70]:\tis_classify: True\n",
            "2019-12-29 21:26:05,221-INFO: is_distributed: False\n",
            "[INFO] 2019-12-29 21:26:05,221 [     args.py:   70]:\tis_distributed: False\n",
            "2019-12-29 21:26:05,221-INFO: is_regression: False\n",
            "[INFO] 2019-12-29 21:26:05,221 [     args.py:   70]:\tis_regression: False\n",
            "2019-12-29 21:26:05,221-INFO: label_map_config: None\n",
            "[INFO] 2019-12-29 21:26:05,221 [     args.py:   70]:\tlabel_map_config: None\n",
            "2019-12-29 21:26:05,221-INFO: learning_rate: 2e-05\n",
            "[INFO] 2019-12-29 21:26:05,221 [     args.py:   70]:\tlearning_rate: 2e-05\n",
            "2019-12-29 21:26:05,221-INFO: lr_scheduler: linear_warmup_decay\n",
            "[INFO] 2019-12-29 21:26:05,221 [     args.py:   70]:\tlr_scheduler: linear_warmup_decay\n",
            "2019-12-29 21:26:05,221-INFO: max_answer_length: 100\n",
            "[INFO] 2019-12-29 21:26:05,221 [     args.py:   70]:\tmax_answer_length: 100\n",
            "2019-12-29 21:26:05,221-INFO: max_query_length: 64\n",
            "[INFO] 2019-12-29 21:26:05,221 [     args.py:   70]:\tmax_query_length: 64\n",
            "2019-12-29 21:26:05,222-INFO: max_seq_len: 128\n",
            "[INFO] 2019-12-29 21:26:05,222 [     args.py:   70]:\tmax_seq_len: 128\n",
            "2019-12-29 21:26:05,222-INFO: metric: simple_accuracy\n",
            "[INFO] 2019-12-29 21:26:05,222 [     args.py:   70]:\tmetric: simple_accuracy\n",
            "2019-12-29 21:26:05,222-INFO: metrics: True\n",
            "[INFO] 2019-12-29 21:26:05,222 [     args.py:   70]:\tmetrics: True\n",
            "2019-12-29 21:26:05,222-INFO: n_best_size: 20\n",
            "[INFO] 2019-12-29 21:26:05,222 [     args.py:   70]:\tn_best_size: 20\n",
            "2019-12-29 21:26:05,222-INFO: num_iteration_per_drop_scope: 1\n",
            "[INFO] 2019-12-29 21:26:05,222 [     args.py:   70]:\tnum_iteration_per_drop_scope: 1\n",
            "2019-12-29 21:26:05,222-INFO: num_labels: 2\n",
            "[INFO] 2019-12-29 21:26:05,222 [     args.py:   70]:\tnum_labels: 2\n",
            "2019-12-29 21:26:05,222-INFO: predict_batch_size: None\n",
            "[INFO] 2019-12-29 21:26:05,222 [     args.py:   70]:\tpredict_batch_size: None\n",
            "2019-12-29 21:26:05,222-INFO: random_seed: 1\n",
            "[INFO] 2019-12-29 21:26:05,222 [     args.py:   70]:\trandom_seed: 1\n",
            "2019-12-29 21:26:05,222-INFO: save_steps: 10000\n",
            "[INFO] 2019-12-29 21:26:05,222 [     args.py:   70]:\tsave_steps: 10000\n",
            "2019-12-29 21:26:05,222-INFO: shuffle: True\n",
            "[INFO] 2019-12-29 21:26:05,222 [     args.py:   70]:\tshuffle: True\n",
            "2019-12-29 21:26:05,222-INFO: skip_steps: 10\n",
            "[INFO] 2019-12-29 21:26:05,222 [     args.py:   70]:\tskip_steps: 10\n",
            "2019-12-29 21:26:05,222-INFO: task_id: 0\n",
            "[INFO] 2019-12-29 21:26:05,222 [     args.py:   70]:\ttask_id: 0\n",
            "2019-12-29 21:26:05,222-INFO: test_save: output/test_out.{1..5}.2e-5.32.4.tsv\n",
            "[INFO] 2019-12-29 21:26:05,222 [     args.py:   70]:\ttest_save: output/test_out.{1..5}.2e-5.32.4.tsv\n",
            "2019-12-29 21:26:05,222-INFO: test_set: dataset/sem-eval/val.tsv\n",
            "[INFO] 2019-12-29 21:26:05,222 [     args.py:   70]:\ttest_set: dataset/sem-eval/val.tsv\n",
            "2019-12-29 21:26:05,222-INFO: tokenizer: FullTokenizer\n",
            "[INFO] 2019-12-29 21:26:05,222 [     args.py:   70]:\ttokenizer: FullTokenizer\n",
            "2019-12-29 21:26:05,222-INFO: train_set: dataset/sem-eval/train.tsv\n",
            "[INFO] 2019-12-29 21:26:05,222 [     args.py:   70]:\ttrain_set: dataset/sem-eval/train.tsv\n",
            "2019-12-29 21:26:05,222-INFO: use_cuda: True\n",
            "[INFO] 2019-12-29 21:26:05,222 [     args.py:   70]:\tuse_cuda: True\n",
            "2019-12-29 21:26:05,222-INFO: use_dynamic_loss_scaling: True\n",
            "[INFO] 2019-12-29 21:26:05,222 [     args.py:   70]:\tuse_dynamic_loss_scaling: True\n",
            "2019-12-29 21:26:05,222-INFO: use_fast_executor: True\n",
            "[INFO] 2019-12-29 21:26:05,222 [     args.py:   70]:\tuse_fast_executor: True\n",
            "2019-12-29 21:26:05,222-INFO: use_fp16: False\n",
            "[INFO] 2019-12-29 21:26:05,222 [     args.py:   70]:\tuse_fp16: False\n",
            "2019-12-29 21:26:05,222-INFO: use_multi_gpu_test: False\n",
            "[INFO] 2019-12-29 21:26:05,222 [     args.py:   70]:\tuse_multi_gpu_test: False\n",
            "2019-12-29 21:26:05,222-INFO: validation_steps: 800000000000\n",
            "[INFO] 2019-12-29 21:26:05,222 [     args.py:   70]:\tvalidation_steps: 800000000000\n",
            "2019-12-29 21:26:05,223-INFO: verbose: True\n",
            "[INFO] 2019-12-29 21:26:05,223 [     args.py:   70]:\tverbose: True\n",
            "2019-12-29 21:26:05,223-INFO: vocab_path: script/en_glue/ernie_base/vocab.txt\n",
            "[INFO] 2019-12-29 21:26:05,223 [     args.py:   70]:\tvocab_path: script/en_glue/ernie_base/vocab.txt\n",
            "2019-12-29 21:26:05,223-INFO: warmup_proportion: 0.1\n",
            "[INFO] 2019-12-29 21:26:05,223 [     args.py:   70]:\twarmup_proportion: 0.1\n",
            "2019-12-29 21:26:05,223-INFO: weight_decay: 0.0\n",
            "[INFO] 2019-12-29 21:26:05,223 [     args.py:   70]:\tweight_decay: 0.0\n",
            "2019-12-29 21:26:05,223-INFO: ------------------------------------------------\n",
            "[INFO] 2019-12-29 21:26:05,223 [     args.py:   71]:\t------------------------------------------------\n",
            "2019-12-29 21:26:05,223-INFO: attention_probs_dropout_prob: 0.1\n",
            "[INFO] 2019-12-29 21:26:05,223 [    ernie.py:   51]:\tattention_probs_dropout_prob: 0.1\n",
            "2019-12-29 21:26:05,223-INFO: hidden_act: gelu\n",
            "[INFO] 2019-12-29 21:26:05,223 [    ernie.py:   51]:\thidden_act: gelu\n",
            "2019-12-29 21:26:05,223-INFO: hidden_dropout_prob: 0.1\n",
            "[INFO] 2019-12-29 21:26:05,223 [    ernie.py:   51]:\thidden_dropout_prob: 0.1\n",
            "2019-12-29 21:26:05,223-INFO: hidden_size: 768\n",
            "[INFO] 2019-12-29 21:26:05,223 [    ernie.py:   51]:\thidden_size: 768\n",
            "2019-12-29 21:26:05,223-INFO: initializer_range: 0.02\n",
            "[INFO] 2019-12-29 21:26:05,223 [    ernie.py:   51]:\tinitializer_range: 0.02\n",
            "2019-12-29 21:26:05,223-INFO: max_position_embeddings: 512\n",
            "[INFO] 2019-12-29 21:26:05,223 [    ernie.py:   51]:\tmax_position_embeddings: 512\n",
            "2019-12-29 21:26:05,223-INFO: num_attention_heads: 12\n",
            "[INFO] 2019-12-29 21:26:05,223 [    ernie.py:   51]:\tnum_attention_heads: 12\n",
            "2019-12-29 21:26:05,223-INFO: num_hidden_layers: 12\n",
            "[INFO] 2019-12-29 21:26:05,223 [    ernie.py:   51]:\tnum_hidden_layers: 12\n",
            "2019-12-29 21:26:05,223-INFO: sent_type_vocab_size: 4\n",
            "[INFO] 2019-12-29 21:26:05,223 [    ernie.py:   51]:\tsent_type_vocab_size: 4\n",
            "2019-12-29 21:26:05,223-INFO: task_type_vocab_size: 16\n",
            "[INFO] 2019-12-29 21:26:05,223 [    ernie.py:   51]:\ttask_type_vocab_size: 16\n",
            "2019-12-29 21:26:05,223-INFO: vocab_size: 30522\n",
            "[INFO] 2019-12-29 21:26:05,223 [    ernie.py:   51]:\tvocab_size: 30522\n",
            "2019-12-29 21:26:05,223-INFO: ------------------------------------------------\n",
            "[INFO] 2019-12-29 21:26:05,223 [    ernie.py:   52]:\t------------------------------------------------\n",
            "2019-12-29 21:26:05,312-INFO: Device count: 1\n",
            "[INFO] 2019-12-29 21:26:05,312 [run_classifier.py:  103]:\tDevice count: 1\n",
            "2019-12-29 21:26:05,312-INFO: Num train examples: 11916\n",
            "[INFO] 2019-12-29 21:26:05,312 [run_classifier.py:  104]:\tNum train examples: 11916\n",
            "2019-12-29 21:26:05,312-INFO: Max train steps: 1489\n",
            "[INFO] 2019-12-29 21:26:05,312 [run_classifier.py:  105]:\tMax train steps: 1489\n",
            "2019-12-29 21:26:05,313-INFO: Num warmup steps: 148\n",
            "[INFO] 2019-12-29 21:26:05,313 [run_classifier.py:  106]:\tNum warmup steps: 148\n",
            "2019-12-29 21:26:05,313-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "[WARNING] 2019-12-29 21:26:05,313 [       io.py:  690]:\tpaddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "2019-12-29 21:26:06,429-INFO: Theoretical memory usage in training: 17039.884 - 17851.307 MB\n",
            "[INFO] 2019-12-29 21:26:06,429 [run_classifier.py:  146]:\tTheoretical memory usage in training: 17039.884 - 17851.307 MB\n",
            "2019-12-29 21:26:06,430-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "[WARNING] 2019-12-29 21:26:06,430 [       io.py:  690]:\tpaddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "W1229 21:26:11.916896  1336 device_context.cc:236] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 10.1, Runtime API Version: 10.0\n",
            "W1229 21:26:11.923048  1336 device_context.cc:244] device: 0, cuDNN Version: 7.6.\n",
            "2019-12-29 21:26:13,342-INFO: Load pretraining parameters from parameters/params/params.\n",
            "[INFO] 2019-12-29 21:26:13,342 [     init.py:   88]:\tLoad pretraining parameters from parameters/params/params.\n",
            "I1229 21:26:13.421072  1336 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
            "I1229 21:26:13.462584  1336 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
            "I1229 21:26:13.528364  1336 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
            "I1229 21:26:13.557648  1336 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
            "2019-12-29 21:26:16,675-INFO: train pyreader queue size: 50, learning rate: 0.000001\n",
            "[INFO] 2019-12-29 21:26:16,675 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000001\n",
            "2019-12-29 21:26:16,676-INFO: epoch: 0, progress: 1984/11916, step: 10, ave loss: 0.713196, ave acc: 0.437500, speed: 3.029823 steps/s\n",
            "[INFO] 2019-12-29 21:26:16,676 [run_classifier.py:  287]:\tepoch: 0, progress: 1984/11916, step: 10, ave loss: 0.713196, ave acc: 0.437500, speed: 3.029823 steps/s\n",
            "2019-12-29 21:26:19,748-INFO: train pyreader queue size: 50, learning rate: 0.000003\n",
            "[INFO] 2019-12-29 21:26:19,748 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000003\n",
            "2019-12-29 21:26:19,749-INFO: epoch: 0, progress: 2304/11916, step: 20, ave loss: 0.622831, ave acc: 0.718750, speed: 3.254125 steps/s\n",
            "[INFO] 2019-12-29 21:26:19,749 [run_classifier.py:  287]:\tepoch: 0, progress: 2304/11916, step: 20, ave loss: 0.622831, ave acc: 0.718750, speed: 3.254125 steps/s\n",
            "2019-12-29 21:26:23,047-INFO: train pyreader queue size: 50, learning rate: 0.000004\n",
            "[INFO] 2019-12-29 21:26:23,047 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000004\n",
            "2019-12-29 21:26:23,047-INFO: epoch: 0, progress: 2624/11916, step: 30, ave loss: 0.613474, ave acc: 0.687500, speed: 3.031844 steps/s\n",
            "[INFO] 2019-12-29 21:26:23,047 [run_classifier.py:  287]:\tepoch: 0, progress: 2624/11916, step: 30, ave loss: 0.613474, ave acc: 0.687500, speed: 3.031844 steps/s\n",
            "2019-12-29 21:26:26,163-INFO: train pyreader queue size: 50, learning rate: 0.000005\n",
            "[INFO] 2019-12-29 21:26:26,163 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000005\n",
            "2019-12-29 21:26:26,164-INFO: epoch: 0, progress: 2944/11916, step: 40, ave loss: 0.587755, ave acc: 0.687500, speed: 3.208823 steps/s\n",
            "[INFO] 2019-12-29 21:26:26,164 [run_classifier.py:  287]:\tepoch: 0, progress: 2944/11916, step: 40, ave loss: 0.587755, ave acc: 0.687500, speed: 3.208823 steps/s\n",
            "2019-12-29 21:26:29,238-INFO: train pyreader queue size: 50, learning rate: 0.000007\n",
            "[INFO] 2019-12-29 21:26:29,238 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000007\n",
            "2019-12-29 21:26:29,238-INFO: epoch: 0, progress: 3264/11916, step: 50, ave loss: 0.624015, ave acc: 0.718750, speed: 3.252601 steps/s\n",
            "[INFO] 2019-12-29 21:26:29,238 [run_classifier.py:  287]:\tepoch: 0, progress: 3264/11916, step: 50, ave loss: 0.624015, ave acc: 0.718750, speed: 3.252601 steps/s\n",
            "2019-12-29 21:26:31,948-INFO: train pyreader queue size: 50, learning rate: 0.000008\n",
            "[INFO] 2019-12-29 21:26:31,948 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000008\n",
            "2019-12-29 21:26:31,948-INFO: epoch: 0, progress: 3584/11916, step: 60, ave loss: 0.617542, ave acc: 0.656250, speed: 3.690509 steps/s\n",
            "[INFO] 2019-12-29 21:26:31,948 [run_classifier.py:  287]:\tepoch: 0, progress: 3584/11916, step: 60, ave loss: 0.617542, ave acc: 0.656250, speed: 3.690509 steps/s\n",
            "2019-12-29 21:26:35,040-INFO: train pyreader queue size: 50, learning rate: 0.000009\n",
            "[INFO] 2019-12-29 21:26:35,040 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000009\n",
            "2019-12-29 21:26:35,040-INFO: epoch: 0, progress: 3904/11916, step: 70, ave loss: 0.471488, ave acc: 0.812500, speed: 3.234285 steps/s\n",
            "[INFO] 2019-12-29 21:26:35,040 [run_classifier.py:  287]:\tepoch: 0, progress: 3904/11916, step: 70, ave loss: 0.471488, ave acc: 0.812500, speed: 3.234285 steps/s\n",
            "2019-12-29 21:26:38,302-INFO: train pyreader queue size: 50, learning rate: 0.000011\n",
            "[INFO] 2019-12-29 21:26:38,302 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000011\n",
            "2019-12-29 21:26:38,302-INFO: epoch: 0, progress: 4224/11916, step: 80, ave loss: 0.478171, ave acc: 0.718750, speed: 3.065928 steps/s\n",
            "[INFO] 2019-12-29 21:26:38,302 [run_classifier.py:  287]:\tepoch: 0, progress: 4224/11916, step: 80, ave loss: 0.478171, ave acc: 0.718750, speed: 3.065928 steps/s\n",
            "2019-12-29 21:26:41,530-INFO: train pyreader queue size: 50, learning rate: 0.000012\n",
            "[INFO] 2019-12-29 21:26:41,530 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000012\n",
            "2019-12-29 21:26:41,531-INFO: epoch: 0, progress: 4544/11916, step: 90, ave loss: 0.350969, ave acc: 0.937500, speed: 3.097269 steps/s\n",
            "[INFO] 2019-12-29 21:26:41,531 [run_classifier.py:  287]:\tepoch: 0, progress: 4544/11916, step: 90, ave loss: 0.350969, ave acc: 0.937500, speed: 3.097269 steps/s\n",
            "2019-12-29 21:26:44,415-INFO: train pyreader queue size: 50, learning rate: 0.000013\n",
            "[INFO] 2019-12-29 21:26:44,415 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000013\n",
            "2019-12-29 21:26:44,415-INFO: epoch: 0, progress: 4864/11916, step: 100, ave loss: 0.463803, ave acc: 0.843750, speed: 3.466498 steps/s\n",
            "[INFO] 2019-12-29 21:26:44,415 [run_classifier.py:  287]:\tepoch: 0, progress: 4864/11916, step: 100, ave loss: 0.463803, ave acc: 0.843750, speed: 3.466498 steps/s\n",
            "2019-12-29 21:26:47,389-INFO: train pyreader queue size: 50, learning rate: 0.000015\n",
            "[INFO] 2019-12-29 21:26:47,389 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000015\n",
            "2019-12-29 21:26:47,390-INFO: epoch: 0, progress: 5184/11916, step: 110, ave loss: 0.430690, ave acc: 0.812500, speed: 3.362376 steps/s\n",
            "[INFO] 2019-12-29 21:26:47,390 [run_classifier.py:  287]:\tepoch: 0, progress: 5184/11916, step: 110, ave loss: 0.430690, ave acc: 0.812500, speed: 3.362376 steps/s\n",
            "2019-12-29 21:26:50,701-INFO: train pyreader queue size: 50, learning rate: 0.000016\n",
            "[INFO] 2019-12-29 21:26:50,701 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000016\n",
            "2019-12-29 21:26:50,702-INFO: epoch: 0, progress: 5504/11916, step: 120, ave loss: 0.479391, ave acc: 0.781250, speed: 3.019367 steps/s\n",
            "[INFO] 2019-12-29 21:26:50,702 [run_classifier.py:  287]:\tepoch: 0, progress: 5504/11916, step: 120, ave loss: 0.479391, ave acc: 0.781250, speed: 3.019367 steps/s\n",
            "2019-12-29 21:26:53,936-INFO: train pyreader queue size: 50, learning rate: 0.000017\n",
            "[INFO] 2019-12-29 21:26:53,936 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000017\n",
            "2019-12-29 21:26:53,936-INFO: epoch: 0, progress: 5824/11916, step: 130, ave loss: 0.698550, ave acc: 0.593750, speed: 3.091889 steps/s\n",
            "[INFO] 2019-12-29 21:26:53,936 [run_classifier.py:  287]:\tepoch: 0, progress: 5824/11916, step: 130, ave loss: 0.698550, ave acc: 0.593750, speed: 3.091889 steps/s\n",
            "2019-12-29 21:26:57,217-INFO: train pyreader queue size: 50, learning rate: 0.000019\n",
            "[INFO] 2019-12-29 21:26:57,217 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000019\n",
            "2019-12-29 21:26:57,217-INFO: epoch: 0, progress: 6144/11916, step: 140, ave loss: 0.409047, ave acc: 0.812500, speed: 3.048195 steps/s\n",
            "[INFO] 2019-12-29 21:26:57,217 [run_classifier.py:  287]:\tepoch: 0, progress: 6144/11916, step: 140, ave loss: 0.409047, ave acc: 0.812500, speed: 3.048195 steps/s\n",
            "2019-12-29 21:27:00,488-INFO: train pyreader queue size: 50, learning rate: 0.000018\n",
            "[INFO] 2019-12-29 21:27:00,488 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000018\n",
            "2019-12-29 21:27:00,488-INFO: epoch: 0, progress: 6464/11916, step: 150, ave loss: 0.385885, ave acc: 0.812500, speed: 3.057112 steps/s\n",
            "[INFO] 2019-12-29 21:27:00,488 [run_classifier.py:  287]:\tepoch: 0, progress: 6464/11916, step: 150, ave loss: 0.385885, ave acc: 0.812500, speed: 3.057112 steps/s\n",
            "2019-12-29 21:27:03,181-INFO: train pyreader queue size: 50, learning rate: 0.000018\n",
            "[INFO] 2019-12-29 21:27:03,181 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000018\n",
            "2019-12-29 21:27:03,182-INFO: epoch: 0, progress: 6784/11916, step: 160, ave loss: 0.408355, ave acc: 0.843750, speed: 3.712669 steps/s\n",
            "[INFO] 2019-12-29 21:27:03,182 [run_classifier.py:  287]:\tepoch: 0, progress: 6784/11916, step: 160, ave loss: 0.408355, ave acc: 0.843750, speed: 3.712669 steps/s\n",
            "2019-12-29 21:27:06,411-INFO: train pyreader queue size: 50, learning rate: 0.000018\n",
            "[INFO] 2019-12-29 21:27:06,411 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000018\n",
            "2019-12-29 21:27:06,411-INFO: epoch: 0, progress: 7104/11916, step: 170, ave loss: 0.352525, ave acc: 0.812500, speed: 3.096384 steps/s\n",
            "[INFO] 2019-12-29 21:27:06,411 [run_classifier.py:  287]:\tepoch: 0, progress: 7104/11916, step: 170, ave loss: 0.352525, ave acc: 0.812500, speed: 3.096384 steps/s\n",
            "2019-12-29 21:27:09,979-INFO: train pyreader queue size: 50, learning rate: 0.000018\n",
            "[INFO] 2019-12-29 21:27:09,979 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000018\n",
            "2019-12-29 21:27:09,980-INFO: epoch: 0, progress: 7424/11916, step: 180, ave loss: 0.365797, ave acc: 0.875000, speed: 2.802408 steps/s\n",
            "[INFO] 2019-12-29 21:27:09,980 [run_classifier.py:  287]:\tepoch: 0, progress: 7424/11916, step: 180, ave loss: 0.365797, ave acc: 0.875000, speed: 2.802408 steps/s\n",
            "2019-12-29 21:27:13,006-INFO: train pyreader queue size: 50, learning rate: 0.000017\n",
            "[INFO] 2019-12-29 21:27:13,006 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000017\n",
            "2019-12-29 21:27:13,007-INFO: epoch: 0, progress: 7744/11916, step: 190, ave loss: 0.420572, ave acc: 0.750000, speed: 3.303618 steps/s\n",
            "[INFO] 2019-12-29 21:27:13,007 [run_classifier.py:  287]:\tepoch: 0, progress: 7744/11916, step: 190, ave loss: 0.420572, ave acc: 0.750000, speed: 3.303618 steps/s\n",
            "2019-12-29 21:27:16,430-INFO: train pyreader queue size: 50, learning rate: 0.000017\n",
            "[INFO] 2019-12-29 21:27:16,430 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000017\n",
            "2019-12-29 21:27:16,431-INFO: epoch: 0, progress: 8064/11916, step: 200, ave loss: 0.388647, ave acc: 0.812500, speed: 2.920766 steps/s\n",
            "[INFO] 2019-12-29 21:27:16,431 [run_classifier.py:  287]:\tepoch: 0, progress: 8064/11916, step: 200, ave loss: 0.388647, ave acc: 0.812500, speed: 2.920766 steps/s\n",
            "2019-12-29 21:27:19,319-INFO: train pyreader queue size: 50, learning rate: 0.000017\n",
            "[INFO] 2019-12-29 21:27:19,319 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000017\n",
            "2019-12-29 21:27:19,319-INFO: epoch: 0, progress: 8384/11916, step: 210, ave loss: 0.528663, ave acc: 0.750000, speed: 3.462557 steps/s\n",
            "[INFO] 2019-12-29 21:27:19,319 [run_classifier.py:  287]:\tepoch: 0, progress: 8384/11916, step: 210, ave loss: 0.528663, ave acc: 0.750000, speed: 3.462557 steps/s\n",
            "2019-12-29 21:27:22,254-INFO: train pyreader queue size: 50, learning rate: 0.000017\n",
            "[INFO] 2019-12-29 21:27:22,254 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000017\n",
            "2019-12-29 21:27:22,255-INFO: epoch: 0, progress: 8704/11916, step: 220, ave loss: 0.514843, ave acc: 0.781250, speed: 3.406523 steps/s\n",
            "[INFO] 2019-12-29 21:27:22,255 [run_classifier.py:  287]:\tepoch: 0, progress: 8704/11916, step: 220, ave loss: 0.514843, ave acc: 0.781250, speed: 3.406523 steps/s\n",
            "2019-12-29 21:27:25,030-INFO: train pyreader queue size: 50, learning rate: 0.000017\n",
            "[INFO] 2019-12-29 21:27:25,030 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000017\n",
            "2019-12-29 21:27:25,030-INFO: epoch: 0, progress: 9024/11916, step: 230, ave loss: 0.344873, ave acc: 0.875000, speed: 3.603466 steps/s\n",
            "[INFO] 2019-12-29 21:27:25,030 [run_classifier.py:  287]:\tepoch: 0, progress: 9024/11916, step: 230, ave loss: 0.344873, ave acc: 0.875000, speed: 3.603466 steps/s\n",
            "2019-12-29 21:27:28,182-INFO: train pyreader queue size: 50, learning rate: 0.000017\n",
            "[INFO] 2019-12-29 21:27:28,182 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000017\n",
            "2019-12-29 21:27:28,182-INFO: epoch: 0, progress: 9344/11916, step: 240, ave loss: 0.408873, ave acc: 0.812500, speed: 3.172265 steps/s\n",
            "[INFO] 2019-12-29 21:27:28,182 [run_classifier.py:  287]:\tepoch: 0, progress: 9344/11916, step: 240, ave loss: 0.408873, ave acc: 0.812500, speed: 3.172265 steps/s\n",
            "2019-12-29 21:27:31,152-INFO: train pyreader queue size: 50, learning rate: 0.000017\n",
            "[INFO] 2019-12-29 21:27:31,152 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000017\n",
            "2019-12-29 21:27:31,153-INFO: epoch: 0, progress: 9664/11916, step: 250, ave loss: 0.298079, ave acc: 0.937500, speed: 3.366856 steps/s\n",
            "[INFO] 2019-12-29 21:27:31,153 [run_classifier.py:  287]:\tepoch: 0, progress: 9664/11916, step: 250, ave loss: 0.298079, ave acc: 0.937500, speed: 3.366856 steps/s\n",
            "2019-12-29 21:27:34,582-INFO: train pyreader queue size: 50, learning rate: 0.000017\n",
            "[INFO] 2019-12-29 21:27:34,582 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000017\n",
            "2019-12-29 21:27:34,582-INFO: epoch: 0, progress: 9984/11916, step: 260, ave loss: 0.428107, ave acc: 0.875000, speed: 2.915868 steps/s\n",
            "[INFO] 2019-12-29 21:27:34,582 [run_classifier.py:  287]:\tepoch: 0, progress: 9984/11916, step: 260, ave loss: 0.428107, ave acc: 0.875000, speed: 2.915868 steps/s\n",
            "2019-12-29 21:27:37,667-INFO: train pyreader queue size: 50, learning rate: 0.000016\n",
            "[INFO] 2019-12-29 21:27:37,667 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000016\n",
            "2019-12-29 21:27:37,668-INFO: epoch: 0, progress: 10304/11916, step: 270, ave loss: 0.463623, ave acc: 0.843750, speed: 3.241079 steps/s\n",
            "[INFO] 2019-12-29 21:27:37,668 [run_classifier.py:  287]:\tepoch: 0, progress: 10304/11916, step: 270, ave loss: 0.463623, ave acc: 0.843750, speed: 3.241079 steps/s\n",
            "2019-12-29 21:27:40,518-INFO: train pyreader queue size: 50, learning rate: 0.000016\n",
            "[INFO] 2019-12-29 21:27:40,518 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000016\n",
            "2019-12-29 21:27:40,518-INFO: epoch: 0, progress: 10624/11916, step: 280, ave loss: 0.273979, ave acc: 0.843750, speed: 3.508723 steps/s\n",
            "[INFO] 2019-12-29 21:27:40,518 [run_classifier.py:  287]:\tepoch: 0, progress: 10624/11916, step: 280, ave loss: 0.273979, ave acc: 0.843750, speed: 3.508723 steps/s\n",
            "2019-12-29 21:27:43,371-INFO: train pyreader queue size: 50, learning rate: 0.000016\n",
            "[INFO] 2019-12-29 21:27:43,371 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000016\n",
            "2019-12-29 21:27:43,371-INFO: epoch: 0, progress: 10944/11916, step: 290, ave loss: 0.312024, ave acc: 0.906250, speed: 3.504754 steps/s\n",
            "[INFO] 2019-12-29 21:27:43,371 [run_classifier.py:  287]:\tepoch: 0, progress: 10944/11916, step: 290, ave loss: 0.312024, ave acc: 0.906250, speed: 3.504754 steps/s\n",
            "2019-12-29 21:27:46,519-INFO: train pyreader queue size: 50, learning rate: 0.000016\n",
            "[INFO] 2019-12-29 21:27:46,519 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000016\n",
            "2019-12-29 21:27:46,519-INFO: epoch: 0, progress: 11264/11916, step: 300, ave loss: 0.376120, ave acc: 0.875000, speed: 3.176735 steps/s\n",
            "[INFO] 2019-12-29 21:27:46,519 [run_classifier.py:  287]:\tepoch: 0, progress: 11264/11916, step: 300, ave loss: 0.376120, ave acc: 0.875000, speed: 3.176735 steps/s\n",
            "2019-12-29 21:27:49,641-INFO: train pyreader queue size: 50, learning rate: 0.000016\n",
            "[INFO] 2019-12-29 21:27:49,641 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000016\n",
            "2019-12-29 21:27:49,641-INFO: epoch: 0, progress: 11584/11916, step: 310, ave loss: 0.440573, ave acc: 0.781250, speed: 3.203231 steps/s\n",
            "[INFO] 2019-12-29 21:27:49,641 [run_classifier.py:  287]:\tepoch: 0, progress: 11584/11916, step: 310, ave loss: 0.440573, ave acc: 0.781250, speed: 3.203231 steps/s\n",
            "2019-12-29 21:27:52,801-INFO: train pyreader queue size: 50, learning rate: 0.000016\n",
            "[INFO] 2019-12-29 21:27:52,801 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000016\n",
            "2019-12-29 21:27:52,801-INFO: epoch: 0, progress: 11904/11916, step: 320, ave loss: 0.509013, ave acc: 0.750000, speed: 3.164705 steps/s\n",
            "[INFO] 2019-12-29 21:27:52,801 [run_classifier.py:  287]:\tepoch: 0, progress: 11904/11916, step: 320, ave loss: 0.509013, ave acc: 0.750000, speed: 3.164705 steps/s\n",
            "2019-12-29 21:27:55,581-INFO: train pyreader queue size: 50, learning rate: 0.000016\n",
            "[INFO] 2019-12-29 21:27:55,581 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000016\n",
            "2019-12-29 21:27:55,581-INFO: epoch: 1, progress: 288/11916, step: 330, ave loss: 0.416922, ave acc: 0.812500, speed: 3.597741 steps/s\n",
            "[INFO] 2019-12-29 21:27:55,581 [run_classifier.py:  287]:\tepoch: 1, progress: 288/11916, step: 330, ave loss: 0.416922, ave acc: 0.812500, speed: 3.597741 steps/s\n",
            "2019-12-29 21:27:55,584-INFO: testing dataset/sem-eval/val.tsv, save to output/test_out.{1..5}.2e-5.32.4.tsv.1.330\n",
            "[INFO] 2019-12-29 21:27:55,584 [run_classifier.py:  421]:\ttesting dataset/sem-eval/val.tsv, save to output/test_out.{1..5}.2e-5.32.4.tsv.1.330\n",
            "2019-12-29 21:28:04,255-INFO: train pyreader queue size: 50, learning rate: 0.000015\n",
            "[INFO] 2019-12-29 21:28:04,255 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000015\n",
            "2019-12-29 21:28:04,256-INFO: epoch: 1, progress: 608/11916, step: 340, ave loss: 0.510919, ave acc: 0.843750, speed: 1.152755 steps/s\n",
            "[INFO] 2019-12-29 21:28:04,256 [run_classifier.py:  287]:\tepoch: 1, progress: 608/11916, step: 340, ave loss: 0.510919, ave acc: 0.843750, speed: 1.152755 steps/s\n",
            "2019-12-29 21:28:07,517-INFO: train pyreader queue size: 50, learning rate: 0.000015\n",
            "[INFO] 2019-12-29 21:28:07,517 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000015\n",
            "2019-12-29 21:28:07,517-INFO: epoch: 1, progress: 928/11916, step: 350, ave loss: 0.359210, ave acc: 0.843750, speed: 3.066369 steps/s\n",
            "[INFO] 2019-12-29 21:28:07,517 [run_classifier.py:  287]:\tepoch: 1, progress: 928/11916, step: 350, ave loss: 0.359210, ave acc: 0.843750, speed: 3.066369 steps/s\n",
            "2019-12-29 21:28:10,642-INFO: train pyreader queue size: 50, learning rate: 0.000015\n",
            "[INFO] 2019-12-29 21:28:10,642 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000015\n",
            "2019-12-29 21:28:10,642-INFO: epoch: 1, progress: 1248/11916, step: 360, ave loss: 0.327679, ave acc: 0.875000, speed: 3.200308 steps/s\n",
            "[INFO] 2019-12-29 21:28:10,642 [run_classifier.py:  287]:\tepoch: 1, progress: 1248/11916, step: 360, ave loss: 0.327679, ave acc: 0.875000, speed: 3.200308 steps/s\n",
            "2019-12-29 21:28:13,977-INFO: train pyreader queue size: 50, learning rate: 0.000015\n",
            "[INFO] 2019-12-29 21:28:13,977 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000015\n",
            "2019-12-29 21:28:13,977-INFO: epoch: 1, progress: 1568/11916, step: 370, ave loss: 0.631618, ave acc: 0.718750, speed: 2.998141 steps/s\n",
            "[INFO] 2019-12-29 21:28:13,977 [run_classifier.py:  287]:\tepoch: 1, progress: 1568/11916, step: 370, ave loss: 0.631618, ave acc: 0.718750, speed: 2.998141 steps/s\n",
            "2019-12-29 21:28:16,787-INFO: train pyreader queue size: 50, learning rate: 0.000015\n",
            "[INFO] 2019-12-29 21:28:16,787 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000015\n",
            "2019-12-29 21:28:16,787-INFO: epoch: 1, progress: 1888/11916, step: 380, ave loss: 0.343713, ave acc: 0.875000, speed: 3.558839 steps/s\n",
            "[INFO] 2019-12-29 21:28:16,787 [run_classifier.py:  287]:\tepoch: 1, progress: 1888/11916, step: 380, ave loss: 0.343713, ave acc: 0.875000, speed: 3.558839 steps/s\n",
            "2019-12-29 21:28:19,676-INFO: train pyreader queue size: 50, learning rate: 0.000015\n",
            "[INFO] 2019-12-29 21:28:19,676 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000015\n",
            "2019-12-29 21:28:19,676-INFO: epoch: 1, progress: 2208/11916, step: 390, ave loss: 0.350070, ave acc: 0.843750, speed: 3.461797 steps/s\n",
            "[INFO] 2019-12-29 21:28:19,676 [run_classifier.py:  287]:\tepoch: 1, progress: 2208/11916, step: 390, ave loss: 0.350070, ave acc: 0.843750, speed: 3.461797 steps/s\n",
            "2019-12-29 21:28:22,760-INFO: train pyreader queue size: 50, learning rate: 0.000015\n",
            "[INFO] 2019-12-29 21:28:22,760 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000015\n",
            "2019-12-29 21:28:22,761-INFO: epoch: 1, progress: 2528/11916, step: 400, ave loss: 0.454603, ave acc: 0.750000, speed: 3.242152 steps/s\n",
            "[INFO] 2019-12-29 21:28:22,761 [run_classifier.py:  287]:\tepoch: 1, progress: 2528/11916, step: 400, ave loss: 0.454603, ave acc: 0.750000, speed: 3.242152 steps/s\n",
            "2019-12-29 21:28:25,962-INFO: train pyreader queue size: 50, learning rate: 0.000015\n",
            "[INFO] 2019-12-29 21:28:25,962 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000015\n",
            "2019-12-29 21:28:25,963-INFO: epoch: 1, progress: 2848/11916, step: 410, ave loss: 0.350446, ave acc: 0.843750, speed: 3.123206 steps/s\n",
            "[INFO] 2019-12-29 21:28:25,963 [run_classifier.py:  287]:\tepoch: 1, progress: 2848/11916, step: 410, ave loss: 0.350446, ave acc: 0.843750, speed: 3.123206 steps/s\n",
            "2019-12-29 21:28:29,547-INFO: train pyreader queue size: 50, learning rate: 0.000014\n",
            "[INFO] 2019-12-29 21:28:29,547 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000014\n",
            "2019-12-29 21:28:29,548-INFO: epoch: 1, progress: 3168/11916, step: 420, ave loss: 0.342241, ave acc: 0.875000, speed: 2.789361 steps/s\n",
            "[INFO] 2019-12-29 21:28:29,548 [run_classifier.py:  287]:\tepoch: 1, progress: 3168/11916, step: 420, ave loss: 0.342241, ave acc: 0.875000, speed: 2.789361 steps/s\n",
            "2019-12-29 21:28:32,822-INFO: train pyreader queue size: 50, learning rate: 0.000014\n",
            "[INFO] 2019-12-29 21:28:32,822 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000014\n",
            "2019-12-29 21:28:32,822-INFO: epoch: 1, progress: 3488/11916, step: 430, ave loss: 0.601204, ave acc: 0.812500, speed: 3.053843 steps/s\n",
            "[INFO] 2019-12-29 21:28:32,822 [run_classifier.py:  287]:\tepoch: 1, progress: 3488/11916, step: 430, ave loss: 0.601204, ave acc: 0.812500, speed: 3.053843 steps/s\n",
            "2019-12-29 21:28:35,957-INFO: train pyreader queue size: 50, learning rate: 0.000014\n",
            "[INFO] 2019-12-29 21:28:35,957 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000014\n",
            "2019-12-29 21:28:35,957-INFO: epoch: 1, progress: 3808/11916, step: 440, ave loss: 0.329330, ave acc: 0.843750, speed: 3.189751 steps/s\n",
            "[INFO] 2019-12-29 21:28:35,957 [run_classifier.py:  287]:\tepoch: 1, progress: 3808/11916, step: 440, ave loss: 0.329330, ave acc: 0.843750, speed: 3.189751 steps/s\n",
            "2019-12-29 21:28:38,805-INFO: train pyreader queue size: 50, learning rate: 0.000014\n",
            "[INFO] 2019-12-29 21:28:38,805 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000014\n",
            "2019-12-29 21:28:38,805-INFO: epoch: 1, progress: 4128/11916, step: 450, ave loss: 0.383237, ave acc: 0.843750, speed: 3.511556 steps/s\n",
            "[INFO] 2019-12-29 21:28:38,805 [run_classifier.py:  287]:\tepoch: 1, progress: 4128/11916, step: 450, ave loss: 0.383237, ave acc: 0.843750, speed: 3.511556 steps/s\n",
            "2019-12-29 21:28:41,657-INFO: train pyreader queue size: 50, learning rate: 0.000014\n",
            "[INFO] 2019-12-29 21:28:41,657 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000014\n",
            "2019-12-29 21:28:41,658-INFO: epoch: 1, progress: 4448/11916, step: 460, ave loss: 0.305774, ave acc: 0.937500, speed: 3.506181 steps/s\n",
            "[INFO] 2019-12-29 21:28:41,658 [run_classifier.py:  287]:\tepoch: 1, progress: 4448/11916, step: 460, ave loss: 0.305774, ave acc: 0.937500, speed: 3.506181 steps/s\n",
            "2019-12-29 21:28:44,944-INFO: train pyreader queue size: 50, learning rate: 0.000014\n",
            "[INFO] 2019-12-29 21:28:44,944 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000014\n",
            "2019-12-29 21:28:44,944-INFO: epoch: 1, progress: 4768/11916, step: 470, ave loss: 0.369921, ave acc: 0.875000, speed: 3.042922 steps/s\n",
            "[INFO] 2019-12-29 21:28:44,944 [run_classifier.py:  287]:\tepoch: 1, progress: 4768/11916, step: 470, ave loss: 0.369921, ave acc: 0.875000, speed: 3.042922 steps/s\n",
            "2019-12-29 21:28:48,187-INFO: train pyreader queue size: 50, learning rate: 0.000014\n",
            "[INFO] 2019-12-29 21:28:48,187 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000014\n",
            "2019-12-29 21:28:48,187-INFO: epoch: 1, progress: 5088/11916, step: 480, ave loss: 0.366429, ave acc: 0.843750, speed: 3.083504 steps/s\n",
            "[INFO] 2019-12-29 21:28:48,187 [run_classifier.py:  287]:\tepoch: 1, progress: 5088/11916, step: 480, ave loss: 0.366429, ave acc: 0.843750, speed: 3.083504 steps/s\n",
            "2019-12-29 21:28:51,126-INFO: train pyreader queue size: 50, learning rate: 0.000013\n",
            "[INFO] 2019-12-29 21:28:51,126 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000013\n",
            "2019-12-29 21:28:51,127-INFO: epoch: 1, progress: 5408/11916, step: 490, ave loss: 0.304834, ave acc: 0.875000, speed: 3.401986 steps/s\n",
            "[INFO] 2019-12-29 21:28:51,127 [run_classifier.py:  287]:\tepoch: 1, progress: 5408/11916, step: 490, ave loss: 0.304834, ave acc: 0.875000, speed: 3.401986 steps/s\n",
            "2019-12-29 21:28:54,253-INFO: train pyreader queue size: 50, learning rate: 0.000013\n",
            "[INFO] 2019-12-29 21:28:54,253 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000013\n",
            "2019-12-29 21:28:54,253-INFO: epoch: 1, progress: 5728/11916, step: 500, ave loss: 0.372320, ave acc: 0.843750, speed: 3.198581 steps/s\n",
            "[INFO] 2019-12-29 21:28:54,253 [run_classifier.py:  287]:\tepoch: 1, progress: 5728/11916, step: 500, ave loss: 0.372320, ave acc: 0.843750, speed: 3.198581 steps/s\n",
            "2019-12-29 21:28:57,453-INFO: train pyreader queue size: 50, learning rate: 0.000013\n",
            "[INFO] 2019-12-29 21:28:57,453 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000013\n",
            "2019-12-29 21:28:57,453-INFO: epoch: 1, progress: 6048/11916, step: 510, ave loss: 0.213661, ave acc: 0.937500, speed: 3.124866 steps/s\n",
            "[INFO] 2019-12-29 21:28:57,453 [run_classifier.py:  287]:\tepoch: 1, progress: 6048/11916, step: 510, ave loss: 0.213661, ave acc: 0.937500, speed: 3.124866 steps/s\n",
            "2019-12-29 21:29:00,366-INFO: train pyreader queue size: 50, learning rate: 0.000013\n",
            "[INFO] 2019-12-29 21:29:00,366 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000013\n",
            "2019-12-29 21:29:00,366-INFO: epoch: 1, progress: 6368/11916, step: 520, ave loss: 0.384381, ave acc: 0.843750, speed: 3.433216 steps/s\n",
            "[INFO] 2019-12-29 21:29:00,366 [run_classifier.py:  287]:\tepoch: 1, progress: 6368/11916, step: 520, ave loss: 0.384381, ave acc: 0.843750, speed: 3.433216 steps/s\n",
            "2019-12-29 21:29:03,466-INFO: train pyreader queue size: 50, learning rate: 0.000013\n",
            "[INFO] 2019-12-29 21:29:03,466 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000013\n",
            "2019-12-29 21:29:03,467-INFO: epoch: 1, progress: 6688/11916, step: 530, ave loss: 0.244418, ave acc: 0.906250, speed: 3.225318 steps/s\n",
            "[INFO] 2019-12-29 21:29:03,467 [run_classifier.py:  287]:\tepoch: 1, progress: 6688/11916, step: 530, ave loss: 0.244418, ave acc: 0.906250, speed: 3.225318 steps/s\n",
            "2019-12-29 21:29:06,301-INFO: train pyreader queue size: 50, learning rate: 0.000013\n",
            "[INFO] 2019-12-29 21:29:06,301 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000013\n",
            "2019-12-29 21:29:06,301-INFO: epoch: 1, progress: 7008/11916, step: 540, ave loss: 0.420637, ave acc: 0.812500, speed: 3.527900 steps/s\n",
            "[INFO] 2019-12-29 21:29:06,301 [run_classifier.py:  287]:\tepoch: 1, progress: 7008/11916, step: 540, ave loss: 0.420637, ave acc: 0.812500, speed: 3.527900 steps/s\n",
            "2019-12-29 21:29:09,188-INFO: train pyreader queue size: 50, learning rate: 0.000013\n",
            "[INFO] 2019-12-29 21:29:09,188 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000013\n",
            "2019-12-29 21:29:09,189-INFO: epoch: 1, progress: 7328/11916, step: 550, ave loss: 0.418154, ave acc: 0.781250, speed: 3.463513 steps/s\n",
            "[INFO] 2019-12-29 21:29:09,189 [run_classifier.py:  287]:\tepoch: 1, progress: 7328/11916, step: 550, ave loss: 0.418154, ave acc: 0.781250, speed: 3.463513 steps/s\n",
            "2019-12-29 21:29:12,175-INFO: train pyreader queue size: 50, learning rate: 0.000012\n",
            "[INFO] 2019-12-29 21:29:12,175 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000012\n",
            "2019-12-29 21:29:12,175-INFO: epoch: 1, progress: 7648/11916, step: 560, ave loss: 0.287926, ave acc: 0.906250, speed: 3.348756 steps/s\n",
            "[INFO] 2019-12-29 21:29:12,175 [run_classifier.py:  287]:\tepoch: 1, progress: 7648/11916, step: 560, ave loss: 0.287926, ave acc: 0.906250, speed: 3.348756 steps/s\n",
            "2019-12-29 21:29:15,229-INFO: train pyreader queue size: 50, learning rate: 0.000012\n",
            "[INFO] 2019-12-29 21:29:15,229 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000012\n",
            "2019-12-29 21:29:15,229-INFO: epoch: 1, progress: 7968/11916, step: 570, ave loss: 0.359632, ave acc: 0.843750, speed: 3.274371 steps/s\n",
            "[INFO] 2019-12-29 21:29:15,229 [run_classifier.py:  287]:\tepoch: 1, progress: 7968/11916, step: 570, ave loss: 0.359632, ave acc: 0.843750, speed: 3.274371 steps/s\n",
            "2019-12-29 21:29:18,593-INFO: train pyreader queue size: 50, learning rate: 0.000012\n",
            "[INFO] 2019-12-29 21:29:18,593 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000012\n",
            "2019-12-29 21:29:18,593-INFO: epoch: 1, progress: 8288/11916, step: 580, ave loss: 0.291415, ave acc: 0.843750, speed: 2.972695 steps/s\n",
            "[INFO] 2019-12-29 21:29:18,593 [run_classifier.py:  287]:\tepoch: 1, progress: 8288/11916, step: 580, ave loss: 0.291415, ave acc: 0.843750, speed: 2.972695 steps/s\n",
            "2019-12-29 21:29:21,688-INFO: train pyreader queue size: 50, learning rate: 0.000012\n",
            "[INFO] 2019-12-29 21:29:21,688 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000012\n",
            "2019-12-29 21:29:21,688-INFO: epoch: 1, progress: 8608/11916, step: 590, ave loss: 0.430710, ave acc: 0.843750, speed: 3.231166 steps/s\n",
            "[INFO] 2019-12-29 21:29:21,688 [run_classifier.py:  287]:\tepoch: 1, progress: 8608/11916, step: 590, ave loss: 0.430710, ave acc: 0.843750, speed: 3.231166 steps/s\n",
            "2019-12-29 21:29:24,872-INFO: train pyreader queue size: 50, learning rate: 0.000012\n",
            "[INFO] 2019-12-29 21:29:24,872 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000012\n",
            "2019-12-29 21:29:24,872-INFO: epoch: 1, progress: 8928/11916, step: 600, ave loss: 0.353634, ave acc: 0.812500, speed: 3.140974 steps/s\n",
            "[INFO] 2019-12-29 21:29:24,872 [run_classifier.py:  287]:\tepoch: 1, progress: 8928/11916, step: 600, ave loss: 0.353634, ave acc: 0.812500, speed: 3.140974 steps/s\n",
            "2019-12-29 21:29:27,839-INFO: train pyreader queue size: 50, learning rate: 0.000012\n",
            "[INFO] 2019-12-29 21:29:27,839 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000012\n",
            "2019-12-29 21:29:27,840-INFO: epoch: 1, progress: 9248/11916, step: 610, ave loss: 0.447718, ave acc: 0.750000, speed: 3.370078 steps/s\n",
            "[INFO] 2019-12-29 21:29:27,840 [run_classifier.py:  287]:\tepoch: 1, progress: 9248/11916, step: 610, ave loss: 0.447718, ave acc: 0.750000, speed: 3.370078 steps/s\n",
            "2019-12-29 21:29:31,508-INFO: train pyreader queue size: 50, learning rate: 0.000012\n",
            "[INFO] 2019-12-29 21:29:31,508 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000012\n",
            "2019-12-29 21:29:31,509-INFO: epoch: 1, progress: 9568/11916, step: 620, ave loss: 0.388562, ave acc: 0.875000, speed: 2.725489 steps/s\n",
            "[INFO] 2019-12-29 21:29:31,509 [run_classifier.py:  287]:\tepoch: 1, progress: 9568/11916, step: 620, ave loss: 0.388562, ave acc: 0.875000, speed: 2.725489 steps/s\n",
            "2019-12-29 21:29:34,601-INFO: train pyreader queue size: 50, learning rate: 0.000012\n",
            "[INFO] 2019-12-29 21:29:34,601 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000012\n",
            "2019-12-29 21:29:34,602-INFO: epoch: 1, progress: 9888/11916, step: 630, ave loss: 0.165336, ave acc: 0.906250, speed: 3.233406 steps/s\n",
            "[INFO] 2019-12-29 21:29:34,602 [run_classifier.py:  287]:\tepoch: 1, progress: 9888/11916, step: 630, ave loss: 0.165336, ave acc: 0.906250, speed: 3.233406 steps/s\n",
            "2019-12-29 21:29:37,579-INFO: train pyreader queue size: 50, learning rate: 0.000011\n",
            "[INFO] 2019-12-29 21:29:37,579 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000011\n",
            "2019-12-29 21:29:37,579-INFO: epoch: 1, progress: 10208/11916, step: 640, ave loss: 0.473835, ave acc: 0.843750, speed: 3.358853 steps/s\n",
            "[INFO] 2019-12-29 21:29:37,579 [run_classifier.py:  287]:\tepoch: 1, progress: 10208/11916, step: 640, ave loss: 0.473835, ave acc: 0.843750, speed: 3.358853 steps/s\n",
            "2019-12-29 21:29:40,697-INFO: train pyreader queue size: 50, learning rate: 0.000011\n",
            "[INFO] 2019-12-29 21:29:40,697 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000011\n",
            "2019-12-29 21:29:40,697-INFO: epoch: 1, progress: 10528/11916, step: 650, ave loss: 0.330379, ave acc: 0.906250, speed: 3.207228 steps/s\n",
            "[INFO] 2019-12-29 21:29:40,697 [run_classifier.py:  287]:\tepoch: 1, progress: 10528/11916, step: 650, ave loss: 0.330379, ave acc: 0.906250, speed: 3.207228 steps/s\n",
            "2019-12-29 21:29:43,886-INFO: train pyreader queue size: 50, learning rate: 0.000011\n",
            "[INFO] 2019-12-29 21:29:43,886 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000011\n",
            "2019-12-29 21:29:43,887-INFO: epoch: 1, progress: 10848/11916, step: 660, ave loss: 0.354700, ave acc: 0.812500, speed: 3.135202 steps/s\n",
            "[INFO] 2019-12-29 21:29:43,887 [run_classifier.py:  287]:\tepoch: 1, progress: 10848/11916, step: 660, ave loss: 0.354700, ave acc: 0.812500, speed: 3.135202 steps/s\n",
            "2019-12-29 21:29:46,858-INFO: train pyreader queue size: 50, learning rate: 0.000011\n",
            "[INFO] 2019-12-29 21:29:46,858 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000011\n",
            "2019-12-29 21:29:46,859-INFO: epoch: 1, progress: 11168/11916, step: 670, ave loss: 0.538543, ave acc: 0.750000, speed: 3.365019 steps/s\n",
            "[INFO] 2019-12-29 21:29:46,859 [run_classifier.py:  287]:\tepoch: 1, progress: 11168/11916, step: 670, ave loss: 0.538543, ave acc: 0.750000, speed: 3.365019 steps/s\n",
            "2019-12-29 21:29:49,834-INFO: train pyreader queue size: 50, learning rate: 0.000011\n",
            "[INFO] 2019-12-29 21:29:49,834 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000011\n",
            "2019-12-29 21:29:49,834-INFO: epoch: 1, progress: 11488/11916, step: 680, ave loss: 0.358671, ave acc: 0.843750, speed: 3.361007 steps/s\n",
            "[INFO] 2019-12-29 21:29:49,834 [run_classifier.py:  287]:\tepoch: 1, progress: 11488/11916, step: 680, ave loss: 0.358671, ave acc: 0.843750, speed: 3.361007 steps/s\n",
            "2019-12-29 21:29:53,064-INFO: train pyreader queue size: 50, learning rate: 0.000011\n",
            "[INFO] 2019-12-29 21:29:53,064 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000011\n",
            "2019-12-29 21:29:53,064-INFO: epoch: 1, progress: 11808/11916, step: 690, ave loss: 0.219541, ave acc: 0.968750, speed: 3.096099 steps/s\n",
            "[INFO] 2019-12-29 21:29:53,064 [run_classifier.py:  287]:\tepoch: 1, progress: 11808/11916, step: 690, ave loss: 0.219541, ave acc: 0.968750, speed: 3.096099 steps/s\n",
            "2019-12-29 21:29:56,298-INFO: train pyreader queue size: 50, learning rate: 0.000011\n",
            "[INFO] 2019-12-29 21:29:56,298 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000011\n",
            "2019-12-29 21:29:56,299-INFO: epoch: 2, progress: 192/11916, step: 700, ave loss: 0.320305, ave acc: 0.875000, speed: 3.091730 steps/s\n",
            "[INFO] 2019-12-29 21:29:56,299 [run_classifier.py:  287]:\tepoch: 2, progress: 192/11916, step: 700, ave loss: 0.320305, ave acc: 0.875000, speed: 3.091730 steps/s\n",
            "2019-12-29 21:29:56,302-INFO: testing dataset/sem-eval/val.tsv, save to output/test_out.{1..5}.2e-5.32.4.tsv.2.700\n",
            "[INFO] 2019-12-29 21:29:56,302 [run_classifier.py:  421]:\ttesting dataset/sem-eval/val.tsv, save to output/test_out.{1..5}.2e-5.32.4.tsv.2.700\n",
            "2019-12-29 21:30:05,092-INFO: train pyreader queue size: 50, learning rate: 0.000010\n",
            "[INFO] 2019-12-29 21:30:05,092 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000010\n",
            "2019-12-29 21:30:05,092-INFO: epoch: 2, progress: 512/11916, step: 710, ave loss: 0.444434, ave acc: 0.750000, speed: 1.137244 steps/s\n",
            "[INFO] 2019-12-29 21:30:05,092 [run_classifier.py:  287]:\tepoch: 2, progress: 512/11916, step: 710, ave loss: 0.444434, ave acc: 0.750000, speed: 1.137244 steps/s\n",
            "2019-12-29 21:30:08,395-INFO: train pyreader queue size: 50, learning rate: 0.000010\n",
            "[INFO] 2019-12-29 21:30:08,395 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000010\n",
            "2019-12-29 21:30:08,395-INFO: epoch: 2, progress: 832/11916, step: 720, ave loss: 0.495418, ave acc: 0.781250, speed: 3.027408 steps/s\n",
            "[INFO] 2019-12-29 21:30:08,395 [run_classifier.py:  287]:\tepoch: 2, progress: 832/11916, step: 720, ave loss: 0.495418, ave acc: 0.781250, speed: 3.027408 steps/s\n",
            "2019-12-29 21:30:11,794-INFO: train pyreader queue size: 50, learning rate: 0.000010\n",
            "[INFO] 2019-12-29 21:30:11,794 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000010\n",
            "2019-12-29 21:30:11,795-INFO: epoch: 2, progress: 1152/11916, step: 730, ave loss: 0.461036, ave acc: 0.843750, speed: 2.941715 steps/s\n",
            "[INFO] 2019-12-29 21:30:11,795 [run_classifier.py:  287]:\tepoch: 2, progress: 1152/11916, step: 730, ave loss: 0.461036, ave acc: 0.843750, speed: 2.941715 steps/s\n",
            "2019-12-29 21:30:14,758-INFO: train pyreader queue size: 50, learning rate: 0.000010\n",
            "[INFO] 2019-12-29 21:30:14,758 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000010\n",
            "2019-12-29 21:30:14,758-INFO: epoch: 2, progress: 1472/11916, step: 740, ave loss: 0.309935, ave acc: 0.906250, speed: 3.374874 steps/s\n",
            "[INFO] 2019-12-29 21:30:14,758 [run_classifier.py:  287]:\tepoch: 2, progress: 1472/11916, step: 740, ave loss: 0.309935, ave acc: 0.906250, speed: 3.374874 steps/s\n",
            "2019-12-29 21:30:17,493-INFO: train pyreader queue size: 50, learning rate: 0.000010\n",
            "[INFO] 2019-12-29 21:30:17,493 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000010\n",
            "2019-12-29 21:30:17,493-INFO: epoch: 2, progress: 1792/11916, step: 750, ave loss: 0.432605, ave acc: 0.781250, speed: 3.655712 steps/s\n",
            "[INFO] 2019-12-29 21:30:17,493 [run_classifier.py:  287]:\tepoch: 2, progress: 1792/11916, step: 750, ave loss: 0.432605, ave acc: 0.781250, speed: 3.655712 steps/s\n",
            "2019-12-29 21:30:20,465-INFO: train pyreader queue size: 50, learning rate: 0.000010\n",
            "[INFO] 2019-12-29 21:30:20,465 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000010\n",
            "2019-12-29 21:30:20,465-INFO: epoch: 2, progress: 2112/11916, step: 760, ave loss: 0.398629, ave acc: 0.781250, speed: 3.365428 steps/s\n",
            "[INFO] 2019-12-29 21:30:20,465 [run_classifier.py:  287]:\tepoch: 2, progress: 2112/11916, step: 760, ave loss: 0.398629, ave acc: 0.781250, speed: 3.365428 steps/s\n",
            "2019-12-29 21:30:23,517-INFO: train pyreader queue size: 50, learning rate: 0.000010\n",
            "[INFO] 2019-12-29 21:30:23,517 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000010\n",
            "2019-12-29 21:30:23,517-INFO: epoch: 2, progress: 2432/11916, step: 770, ave loss: 0.162767, ave acc: 0.937500, speed: 3.276496 steps/s\n",
            "[INFO] 2019-12-29 21:30:23,517 [run_classifier.py:  287]:\tepoch: 2, progress: 2432/11916, step: 770, ave loss: 0.162767, ave acc: 0.937500, speed: 3.276496 steps/s\n",
            "2019-12-29 21:30:26,006-INFO: train pyreader queue size: 50, learning rate: 0.000010\n",
            "[INFO] 2019-12-29 21:30:26,006 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000010\n",
            "2019-12-29 21:30:26,006-INFO: epoch: 2, progress: 2752/11916, step: 780, ave loss: 0.280320, ave acc: 0.843750, speed: 4.017917 steps/s\n",
            "[INFO] 2019-12-29 21:30:26,006 [run_classifier.py:  287]:\tepoch: 2, progress: 2752/11916, step: 780, ave loss: 0.280320, ave acc: 0.843750, speed: 4.017917 steps/s\n",
            "2019-12-29 21:30:28,920-INFO: train pyreader queue size: 50, learning rate: 0.000009\n",
            "[INFO] 2019-12-29 21:30:28,920 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000009\n",
            "2019-12-29 21:30:28,920-INFO: epoch: 2, progress: 3072/11916, step: 790, ave loss: 0.205917, ave acc: 0.937500, speed: 3.431942 steps/s\n",
            "[INFO] 2019-12-29 21:30:28,920 [run_classifier.py:  287]:\tepoch: 2, progress: 3072/11916, step: 790, ave loss: 0.205917, ave acc: 0.937500, speed: 3.431942 steps/s\n",
            "2019-12-29 21:30:31,950-INFO: train pyreader queue size: 50, learning rate: 0.000009\n",
            "[INFO] 2019-12-29 21:30:31,950 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000009\n",
            "2019-12-29 21:30:31,950-INFO: epoch: 2, progress: 3392/11916, step: 800, ave loss: 0.583540, ave acc: 0.750000, speed: 3.300351 steps/s\n",
            "[INFO] 2019-12-29 21:30:31,950 [run_classifier.py:  287]:\tepoch: 2, progress: 3392/11916, step: 800, ave loss: 0.583540, ave acc: 0.750000, speed: 3.300351 steps/s\n",
            "2019-12-29 21:30:35,299-INFO: train pyreader queue size: 50, learning rate: 0.000009\n",
            "[INFO] 2019-12-29 21:30:35,299 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000009\n",
            "2019-12-29 21:30:35,299-INFO: epoch: 2, progress: 3712/11916, step: 810, ave loss: 0.312402, ave acc: 0.875000, speed: 2.985841 steps/s\n",
            "[INFO] 2019-12-29 21:30:35,299 [run_classifier.py:  287]:\tepoch: 2, progress: 3712/11916, step: 810, ave loss: 0.312402, ave acc: 0.875000, speed: 2.985841 steps/s\n",
            "2019-12-29 21:30:38,799-INFO: train pyreader queue size: 50, learning rate: 0.000009\n",
            "[INFO] 2019-12-29 21:30:38,799 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000009\n",
            "2019-12-29 21:30:38,800-INFO: epoch: 2, progress: 4032/11916, step: 820, ave loss: 0.162762, ave acc: 0.937500, speed: 2.857072 steps/s\n",
            "[INFO] 2019-12-29 21:30:38,800 [run_classifier.py:  287]:\tepoch: 2, progress: 4032/11916, step: 820, ave loss: 0.162762, ave acc: 0.937500, speed: 2.857072 steps/s\n",
            "2019-12-29 21:30:41,980-INFO: train pyreader queue size: 50, learning rate: 0.000009\n",
            "[INFO] 2019-12-29 21:30:41,980 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000009\n",
            "2019-12-29 21:30:41,980-INFO: epoch: 2, progress: 4352/11916, step: 830, ave loss: 0.176871, ave acc: 0.906250, speed: 3.144491 steps/s\n",
            "[INFO] 2019-12-29 21:30:41,980 [run_classifier.py:  287]:\tepoch: 2, progress: 4352/11916, step: 830, ave loss: 0.176871, ave acc: 0.906250, speed: 3.144491 steps/s\n",
            "2019-12-29 21:30:44,799-INFO: train pyreader queue size: 50, learning rate: 0.000009\n",
            "[INFO] 2019-12-29 21:30:44,799 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000009\n",
            "2019-12-29 21:30:44,799-INFO: epoch: 2, progress: 4672/11916, step: 840, ave loss: 0.165356, ave acc: 0.906250, speed: 3.547165 steps/s\n",
            "[INFO] 2019-12-29 21:30:44,799 [run_classifier.py:  287]:\tepoch: 2, progress: 4672/11916, step: 840, ave loss: 0.165356, ave acc: 0.906250, speed: 3.547165 steps/s\n",
            "2019-12-29 21:30:48,104-INFO: train pyreader queue size: 50, learning rate: 0.000009\n",
            "[INFO] 2019-12-29 21:30:48,104 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000009\n",
            "2019-12-29 21:30:48,104-INFO: epoch: 2, progress: 4992/11916, step: 850, ave loss: 0.382944, ave acc: 0.843750, speed: 3.025829 steps/s\n",
            "[INFO] 2019-12-29 21:30:48,104 [run_classifier.py:  287]:\tepoch: 2, progress: 4992/11916, step: 850, ave loss: 0.382944, ave acc: 0.843750, speed: 3.025829 steps/s\n",
            "2019-12-29 21:30:51,268-INFO: train pyreader queue size: 50, learning rate: 0.000008\n",
            "[INFO] 2019-12-29 21:30:51,268 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000008\n",
            "2019-12-29 21:30:51,268-INFO: epoch: 2, progress: 5312/11916, step: 860, ave loss: 0.251800, ave acc: 0.906250, speed: 3.160799 steps/s\n",
            "[INFO] 2019-12-29 21:30:51,268 [run_classifier.py:  287]:\tepoch: 2, progress: 5312/11916, step: 860, ave loss: 0.251800, ave acc: 0.906250, speed: 3.160799 steps/s\n",
            "2019-12-29 21:30:54,386-INFO: train pyreader queue size: 50, learning rate: 0.000008\n",
            "[INFO] 2019-12-29 21:30:54,386 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000008\n",
            "2019-12-29 21:30:54,386-INFO: epoch: 2, progress: 5632/11916, step: 870, ave loss: 0.313942, ave acc: 0.875000, speed: 3.207548 steps/s\n",
            "[INFO] 2019-12-29 21:30:54,386 [run_classifier.py:  287]:\tepoch: 2, progress: 5632/11916, step: 870, ave loss: 0.313942, ave acc: 0.875000, speed: 3.207548 steps/s\n",
            "2019-12-29 21:30:57,192-INFO: train pyreader queue size: 50, learning rate: 0.000008\n",
            "[INFO] 2019-12-29 21:30:57,192 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000008\n",
            "2019-12-29 21:30:57,192-INFO: epoch: 2, progress: 5952/11916, step: 880, ave loss: 0.282858, ave acc: 0.968750, speed: 3.564014 steps/s\n",
            "[INFO] 2019-12-29 21:30:57,192 [run_classifier.py:  287]:\tepoch: 2, progress: 5952/11916, step: 880, ave loss: 0.282858, ave acc: 0.968750, speed: 3.564014 steps/s\n",
            "2019-12-29 21:31:00,518-INFO: train pyreader queue size: 50, learning rate: 0.000008\n",
            "[INFO] 2019-12-29 21:31:00,518 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000008\n",
            "2019-12-29 21:31:00,518-INFO: epoch: 2, progress: 6272/11916, step: 890, ave loss: 0.096029, ave acc: 0.968750, speed: 3.006500 steps/s\n",
            "[INFO] 2019-12-29 21:31:00,518 [run_classifier.py:  287]:\tepoch: 2, progress: 6272/11916, step: 890, ave loss: 0.096029, ave acc: 0.968750, speed: 3.006500 steps/s\n",
            "2019-12-29 21:31:03,366-INFO: train pyreader queue size: 50, learning rate: 0.000008\n",
            "[INFO] 2019-12-29 21:31:03,366 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000008\n",
            "2019-12-29 21:31:03,366-INFO: epoch: 2, progress: 6592/11916, step: 900, ave loss: 0.141907, ave acc: 0.937500, speed: 3.511000 steps/s\n",
            "[INFO] 2019-12-29 21:31:03,366 [run_classifier.py:  287]:\tepoch: 2, progress: 6592/11916, step: 900, ave loss: 0.141907, ave acc: 0.937500, speed: 3.511000 steps/s\n",
            "2019-12-29 21:31:06,448-INFO: train pyreader queue size: 50, learning rate: 0.000008\n",
            "[INFO] 2019-12-29 21:31:06,448 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000008\n",
            "2019-12-29 21:31:06,449-INFO: epoch: 2, progress: 6912/11916, step: 910, ave loss: 0.282054, ave acc: 0.906250, speed: 3.244473 steps/s\n",
            "[INFO] 2019-12-29 21:31:06,449 [run_classifier.py:  287]:\tepoch: 2, progress: 6912/11916, step: 910, ave loss: 0.282054, ave acc: 0.906250, speed: 3.244473 steps/s\n",
            "2019-12-29 21:31:09,647-INFO: train pyreader queue size: 50, learning rate: 0.000008\n",
            "[INFO] 2019-12-29 21:31:09,647 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000008\n",
            "2019-12-29 21:31:09,647-INFO: epoch: 2, progress: 7232/11916, step: 920, ave loss: 0.274390, ave acc: 0.937500, speed: 3.126776 steps/s\n",
            "[INFO] 2019-12-29 21:31:09,647 [run_classifier.py:  287]:\tepoch: 2, progress: 7232/11916, step: 920, ave loss: 0.274390, ave acc: 0.937500, speed: 3.126776 steps/s\n",
            "2019-12-29 21:31:12,870-INFO: train pyreader queue size: 50, learning rate: 0.000008\n",
            "[INFO] 2019-12-29 21:31:12,870 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000008\n",
            "2019-12-29 21:31:12,870-INFO: epoch: 2, progress: 7552/11916, step: 930, ave loss: 0.399866, ave acc: 0.843750, speed: 3.102703 steps/s\n",
            "[INFO] 2019-12-29 21:31:12,870 [run_classifier.py:  287]:\tepoch: 2, progress: 7552/11916, step: 930, ave loss: 0.399866, ave acc: 0.843750, speed: 3.102703 steps/s\n",
            "2019-12-29 21:31:16,111-INFO: train pyreader queue size: 50, learning rate: 0.000007\n",
            "[INFO] 2019-12-29 21:31:16,111 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000007\n",
            "2019-12-29 21:31:16,111-INFO: epoch: 2, progress: 7872/11916, step: 940, ave loss: 0.383594, ave acc: 0.812500, speed: 3.085507 steps/s\n",
            "[INFO] 2019-12-29 21:31:16,111 [run_classifier.py:  287]:\tepoch: 2, progress: 7872/11916, step: 940, ave loss: 0.383594, ave acc: 0.812500, speed: 3.085507 steps/s\n",
            "2019-12-29 21:31:18,995-INFO: train pyreader queue size: 50, learning rate: 0.000007\n",
            "[INFO] 2019-12-29 21:31:18,995 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000007\n",
            "2019-12-29 21:31:18,995-INFO: epoch: 2, progress: 8192/11916, step: 950, ave loss: 0.450647, ave acc: 0.812500, speed: 3.467963 steps/s\n",
            "[INFO] 2019-12-29 21:31:18,995 [run_classifier.py:  287]:\tepoch: 2, progress: 8192/11916, step: 950, ave loss: 0.450647, ave acc: 0.812500, speed: 3.467963 steps/s\n",
            "2019-12-29 21:31:22,042-INFO: train pyreader queue size: 50, learning rate: 0.000007\n",
            "[INFO] 2019-12-29 21:31:22,042 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000007\n",
            "2019-12-29 21:31:22,042-INFO: epoch: 2, progress: 8512/11916, step: 960, ave loss: 0.511466, ave acc: 0.843750, speed: 3.281543 steps/s\n",
            "[INFO] 2019-12-29 21:31:22,042 [run_classifier.py:  287]:\tepoch: 2, progress: 8512/11916, step: 960, ave loss: 0.511466, ave acc: 0.843750, speed: 3.281543 steps/s\n",
            "2019-12-29 21:31:24,947-INFO: train pyreader queue size: 50, learning rate: 0.000007\n",
            "[INFO] 2019-12-29 21:31:24,947 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000007\n",
            "2019-12-29 21:31:24,947-INFO: epoch: 2, progress: 8832/11916, step: 970, ave loss: 0.146434, ave acc: 0.937500, speed: 3.442716 steps/s\n",
            "[INFO] 2019-12-29 21:31:24,947 [run_classifier.py:  287]:\tepoch: 2, progress: 8832/11916, step: 970, ave loss: 0.146434, ave acc: 0.937500, speed: 3.442716 steps/s\n",
            "2019-12-29 21:31:28,365-INFO: train pyreader queue size: 50, learning rate: 0.000007\n",
            "[INFO] 2019-12-29 21:31:28,365 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000007\n",
            "2019-12-29 21:31:28,366-INFO: epoch: 2, progress: 9152/11916, step: 980, ave loss: 0.211956, ave acc: 0.906250, speed: 2.925381 steps/s\n",
            "[INFO] 2019-12-29 21:31:28,366 [run_classifier.py:  287]:\tepoch: 2, progress: 9152/11916, step: 980, ave loss: 0.211956, ave acc: 0.906250, speed: 2.925381 steps/s\n",
            "2019-12-29 21:31:31,510-INFO: train pyreader queue size: 50, learning rate: 0.000007\n",
            "[INFO] 2019-12-29 21:31:31,510 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000007\n",
            "2019-12-29 21:31:31,511-INFO: epoch: 2, progress: 9472/11916, step: 990, ave loss: 0.212475, ave acc: 0.937500, speed: 3.179897 steps/s\n",
            "[INFO] 2019-12-29 21:31:31,511 [run_classifier.py:  287]:\tepoch: 2, progress: 9472/11916, step: 990, ave loss: 0.212475, ave acc: 0.937500, speed: 3.179897 steps/s\n",
            "2019-12-29 21:31:34,696-INFO: train pyreader queue size: 50, learning rate: 0.000007\n",
            "[INFO] 2019-12-29 21:31:34,696 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000007\n",
            "2019-12-29 21:31:34,696-INFO: epoch: 2, progress: 9792/11916, step: 1000, ave loss: 0.313707, ave acc: 0.906250, speed: 3.139151 steps/s\n",
            "[INFO] 2019-12-29 21:31:34,696 [run_classifier.py:  287]:\tepoch: 2, progress: 9792/11916, step: 1000, ave loss: 0.313707, ave acc: 0.906250, speed: 3.139151 steps/s\n",
            "2019-12-29 21:31:37,969-INFO: train pyreader queue size: 50, learning rate: 0.000006\n",
            "[INFO] 2019-12-29 21:31:37,969 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000006\n",
            "2019-12-29 21:31:37,969-INFO: epoch: 2, progress: 10112/11916, step: 1010, ave loss: 0.259888, ave acc: 0.968750, speed: 3.055249 steps/s\n",
            "[INFO] 2019-12-29 21:31:37,969 [run_classifier.py:  287]:\tepoch: 2, progress: 10112/11916, step: 1010, ave loss: 0.259888, ave acc: 0.968750, speed: 3.055249 steps/s\n",
            "2019-12-29 21:31:41,312-INFO: train pyreader queue size: 50, learning rate: 0.000006\n",
            "[INFO] 2019-12-29 21:31:41,312 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000006\n",
            "2019-12-29 21:31:41,313-INFO: epoch: 2, progress: 10432/11916, step: 1020, ave loss: 0.286154, ave acc: 0.906250, speed: 2.991203 steps/s\n",
            "[INFO] 2019-12-29 21:31:41,313 [run_classifier.py:  287]:\tepoch: 2, progress: 10432/11916, step: 1020, ave loss: 0.286154, ave acc: 0.906250, speed: 2.991203 steps/s\n",
            "2019-12-29 21:31:44,353-INFO: train pyreader queue size: 50, learning rate: 0.000006\n",
            "[INFO] 2019-12-29 21:31:44,353 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000006\n",
            "2019-12-29 21:31:44,353-INFO: epoch: 2, progress: 10752/11916, step: 1030, ave loss: 0.300108, ave acc: 0.875000, speed: 3.289051 steps/s\n",
            "[INFO] 2019-12-29 21:31:44,353 [run_classifier.py:  287]:\tepoch: 2, progress: 10752/11916, step: 1030, ave loss: 0.300108, ave acc: 0.875000, speed: 3.289051 steps/s\n",
            "2019-12-29 21:31:47,298-INFO: train pyreader queue size: 50, learning rate: 0.000006\n",
            "[INFO] 2019-12-29 21:31:47,298 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000006\n",
            "2019-12-29 21:31:47,298-INFO: epoch: 2, progress: 11072/11916, step: 1040, ave loss: 0.227498, ave acc: 0.875000, speed: 3.395566 steps/s\n",
            "[INFO] 2019-12-29 21:31:47,298 [run_classifier.py:  287]:\tepoch: 2, progress: 11072/11916, step: 1040, ave loss: 0.227498, ave acc: 0.875000, speed: 3.395566 steps/s\n",
            "2019-12-29 21:31:50,750-INFO: train pyreader queue size: 50, learning rate: 0.000006\n",
            "[INFO] 2019-12-29 21:31:50,750 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000006\n",
            "2019-12-29 21:31:50,750-INFO: epoch: 2, progress: 11392/11916, step: 1050, ave loss: 0.205983, ave acc: 0.968750, speed: 2.897221 steps/s\n",
            "[INFO] 2019-12-29 21:31:50,750 [run_classifier.py:  287]:\tepoch: 2, progress: 11392/11916, step: 1050, ave loss: 0.205983, ave acc: 0.968750, speed: 2.897221 steps/s\n",
            "2019-12-29 21:31:53,894-INFO: train pyreader queue size: 50, learning rate: 0.000006\n",
            "[INFO] 2019-12-29 21:31:53,894 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000006\n",
            "2019-12-29 21:31:53,895-INFO: epoch: 2, progress: 11712/11916, step: 1060, ave loss: 0.343381, ave acc: 0.843750, speed: 3.180013 steps/s\n",
            "[INFO] 2019-12-29 21:31:53,895 [run_classifier.py:  287]:\tepoch: 2, progress: 11712/11916, step: 1060, ave loss: 0.343381, ave acc: 0.843750, speed: 3.180013 steps/s\n",
            "2019-12-29 21:31:56,550-INFO: train pyreader queue size: 50, learning rate: 0.000006\n",
            "[INFO] 2019-12-29 21:31:56,550 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000006\n",
            "2019-12-29 21:31:56,550-INFO: epoch: 3, progress: 96/11916, step: 1070, ave loss: 0.274782, ave acc: 0.875000, speed: 3.765756 steps/s\n",
            "[INFO] 2019-12-29 21:31:56,550 [run_classifier.py:  287]:\tepoch: 3, progress: 96/11916, step: 1070, ave loss: 0.274782, ave acc: 0.875000, speed: 3.765756 steps/s\n",
            "2019-12-29 21:31:56,554-INFO: testing dataset/sem-eval/val.tsv, save to output/test_out.{1..5}.2e-5.32.4.tsv.3.1070\n",
            "[INFO] 2019-12-29 21:31:56,554 [run_classifier.py:  421]:\ttesting dataset/sem-eval/val.tsv, save to output/test_out.{1..5}.2e-5.32.4.tsv.3.1070\n",
            "2019-12-29 21:32:05,092-INFO: train pyreader queue size: 50, learning rate: 0.000006\n",
            "[INFO] 2019-12-29 21:32:05,092 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000006\n",
            "2019-12-29 21:32:05,092-INFO: epoch: 3, progress: 416/11916, step: 1080, ave loss: 0.687475, ave acc: 0.718750, speed: 1.170700 steps/s\n",
            "[INFO] 2019-12-29 21:32:05,092 [run_classifier.py:  287]:\tepoch: 3, progress: 416/11916, step: 1080, ave loss: 0.687475, ave acc: 0.718750, speed: 1.170700 steps/s\n",
            "2019-12-29 21:32:08,037-INFO: train pyreader queue size: 50, learning rate: 0.000005\n",
            "[INFO] 2019-12-29 21:32:08,037 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000005\n",
            "2019-12-29 21:32:08,037-INFO: epoch: 3, progress: 736/11916, step: 1090, ave loss: 0.115910, ave acc: 0.968750, speed: 3.395655 steps/s\n",
            "[INFO] 2019-12-29 21:32:08,037 [run_classifier.py:  287]:\tepoch: 3, progress: 736/11916, step: 1090, ave loss: 0.115910, ave acc: 0.968750, speed: 3.395655 steps/s\n",
            "2019-12-29 21:32:10,903-INFO: train pyreader queue size: 50, learning rate: 0.000005\n",
            "[INFO] 2019-12-29 21:32:10,903 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000005\n",
            "2019-12-29 21:32:10,903-INFO: epoch: 3, progress: 1056/11916, step: 1100, ave loss: 0.166912, ave acc: 0.937500, speed: 3.489999 steps/s\n",
            "[INFO] 2019-12-29 21:32:10,903 [run_classifier.py:  287]:\tepoch: 3, progress: 1056/11916, step: 1100, ave loss: 0.166912, ave acc: 0.937500, speed: 3.489999 steps/s\n",
            "2019-12-29 21:32:14,129-INFO: train pyreader queue size: 50, learning rate: 0.000005\n",
            "[INFO] 2019-12-29 21:32:14,129 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000005\n",
            "2019-12-29 21:32:14,130-INFO: epoch: 3, progress: 1376/11916, step: 1110, ave loss: 0.318638, ave acc: 0.906250, speed: 3.099252 steps/s\n",
            "[INFO] 2019-12-29 21:32:14,130 [run_classifier.py:  287]:\tepoch: 3, progress: 1376/11916, step: 1110, ave loss: 0.318638, ave acc: 0.906250, speed: 3.099252 steps/s\n",
            "2019-12-29 21:32:16,989-INFO: train pyreader queue size: 50, learning rate: 0.000005\n",
            "[INFO] 2019-12-29 21:32:16,989 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000005\n",
            "2019-12-29 21:32:16,989-INFO: epoch: 3, progress: 1696/11916, step: 1120, ave loss: 0.216351, ave acc: 0.875000, speed: 3.497035 steps/s\n",
            "[INFO] 2019-12-29 21:32:16,989 [run_classifier.py:  287]:\tepoch: 3, progress: 1696/11916, step: 1120, ave loss: 0.216351, ave acc: 0.875000, speed: 3.497035 steps/s\n",
            "2019-12-29 21:32:20,229-INFO: train pyreader queue size: 50, learning rate: 0.000005\n",
            "[INFO] 2019-12-29 21:32:20,229 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000005\n",
            "2019-12-29 21:32:20,229-INFO: epoch: 3, progress: 2016/11916, step: 1130, ave loss: 0.177976, ave acc: 0.937500, speed: 3.086702 steps/s\n",
            "[INFO] 2019-12-29 21:32:20,229 [run_classifier.py:  287]:\tepoch: 3, progress: 2016/11916, step: 1130, ave loss: 0.177976, ave acc: 0.937500, speed: 3.086702 steps/s\n",
            "2019-12-29 21:32:23,760-INFO: train pyreader queue size: 50, learning rate: 0.000005\n",
            "[INFO] 2019-12-29 21:32:23,760 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000005\n",
            "2019-12-29 21:32:23,760-INFO: epoch: 3, progress: 2336/11916, step: 1140, ave loss: 0.242389, ave acc: 0.875000, speed: 2.831961 steps/s\n",
            "[INFO] 2019-12-29 21:32:23,760 [run_classifier.py:  287]:\tepoch: 3, progress: 2336/11916, step: 1140, ave loss: 0.242389, ave acc: 0.875000, speed: 2.831961 steps/s\n",
            "2019-12-29 21:32:27,034-INFO: train pyreader queue size: 50, learning rate: 0.000005\n",
            "[INFO] 2019-12-29 21:32:27,034 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000005\n",
            "2019-12-29 21:32:27,035-INFO: epoch: 3, progress: 2656/11916, step: 1150, ave loss: 0.271143, ave acc: 0.906250, speed: 3.054249 steps/s\n",
            "[INFO] 2019-12-29 21:32:27,035 [run_classifier.py:  287]:\tepoch: 3, progress: 2656/11916, step: 1150, ave loss: 0.271143, ave acc: 0.906250, speed: 3.054249 steps/s\n",
            "2019-12-29 21:32:30,056-INFO: train pyreader queue size: 50, learning rate: 0.000004\n",
            "[INFO] 2019-12-29 21:32:30,056 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000004\n",
            "2019-12-29 21:32:30,056-INFO: epoch: 3, progress: 2976/11916, step: 1160, ave loss: 0.092763, ave acc: 1.000000, speed: 3.310181 steps/s\n",
            "[INFO] 2019-12-29 21:32:30,056 [run_classifier.py:  287]:\tepoch: 3, progress: 2976/11916, step: 1160, ave loss: 0.092763, ave acc: 1.000000, speed: 3.310181 steps/s\n",
            "2019-12-29 21:32:33,156-INFO: train pyreader queue size: 50, learning rate: 0.000004\n",
            "[INFO] 2019-12-29 21:32:33,156 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000004\n",
            "2019-12-29 21:32:33,156-INFO: epoch: 3, progress: 3296/11916, step: 1170, ave loss: 0.298858, ave acc: 0.875000, speed: 3.225630 steps/s\n",
            "[INFO] 2019-12-29 21:32:33,156 [run_classifier.py:  287]:\tepoch: 3, progress: 3296/11916, step: 1170, ave loss: 0.298858, ave acc: 0.875000, speed: 3.225630 steps/s\n",
            "2019-12-29 21:32:36,261-INFO: train pyreader queue size: 50, learning rate: 0.000004\n",
            "[INFO] 2019-12-29 21:32:36,261 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000004\n",
            "2019-12-29 21:32:36,262-INFO: epoch: 3, progress: 3616/11916, step: 1180, ave loss: 0.193581, ave acc: 0.906250, speed: 3.220115 steps/s\n",
            "[INFO] 2019-12-29 21:32:36,262 [run_classifier.py:  287]:\tepoch: 3, progress: 3616/11916, step: 1180, ave loss: 0.193581, ave acc: 0.906250, speed: 3.220115 steps/s\n",
            "2019-12-29 21:32:39,662-INFO: train pyreader queue size: 50, learning rate: 0.000004\n",
            "[INFO] 2019-12-29 21:32:39,662 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000004\n",
            "2019-12-29 21:32:39,663-INFO: epoch: 3, progress: 3936/11916, step: 1190, ave loss: 0.145355, ave acc: 0.968750, speed: 2.940396 steps/s\n",
            "[INFO] 2019-12-29 21:32:39,663 [run_classifier.py:  287]:\tepoch: 3, progress: 3936/11916, step: 1190, ave loss: 0.145355, ave acc: 0.968750, speed: 2.940396 steps/s\n",
            "2019-12-29 21:32:42,693-INFO: train pyreader queue size: 50, learning rate: 0.000004\n",
            "[INFO] 2019-12-29 21:32:42,693 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000004\n",
            "2019-12-29 21:32:42,694-INFO: epoch: 3, progress: 4256/11916, step: 1200, ave loss: 0.243882, ave acc: 0.906250, speed: 3.299531 steps/s\n",
            "[INFO] 2019-12-29 21:32:42,694 [run_classifier.py:  287]:\tepoch: 3, progress: 4256/11916, step: 1200, ave loss: 0.243882, ave acc: 0.906250, speed: 3.299531 steps/s\n",
            "2019-12-29 21:32:45,761-INFO: train pyreader queue size: 50, learning rate: 0.000004\n",
            "[INFO] 2019-12-29 21:32:45,761 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000004\n",
            "2019-12-29 21:32:45,762-INFO: epoch: 3, progress: 4576/11916, step: 1210, ave loss: 0.142917, ave acc: 0.937500, speed: 3.259635 steps/s\n",
            "[INFO] 2019-12-29 21:32:45,762 [run_classifier.py:  287]:\tepoch: 3, progress: 4576/11916, step: 1210, ave loss: 0.142917, ave acc: 0.937500, speed: 3.259635 steps/s\n",
            "2019-12-29 21:32:48,974-INFO: train pyreader queue size: 50, learning rate: 0.000004\n",
            "[INFO] 2019-12-29 21:32:48,974 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000004\n",
            "2019-12-29 21:32:48,974-INFO: epoch: 3, progress: 4896/11916, step: 1220, ave loss: 0.109721, ave acc: 0.968750, speed: 3.112757 steps/s\n",
            "[INFO] 2019-12-29 21:32:48,974 [run_classifier.py:  287]:\tepoch: 3, progress: 4896/11916, step: 1220, ave loss: 0.109721, ave acc: 0.968750, speed: 3.112757 steps/s\n",
            "2019-12-29 21:32:51,942-INFO: train pyreader queue size: 50, learning rate: 0.000003\n",
            "[INFO] 2019-12-29 21:32:51,942 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000003\n",
            "2019-12-29 21:32:51,943-INFO: epoch: 3, progress: 5216/11916, step: 1230, ave loss: 0.453766, ave acc: 0.812500, speed: 3.369067 steps/s\n",
            "[INFO] 2019-12-29 21:32:51,943 [run_classifier.py:  287]:\tepoch: 3, progress: 5216/11916, step: 1230, ave loss: 0.453766, ave acc: 0.812500, speed: 3.369067 steps/s\n",
            "2019-12-29 21:32:55,029-INFO: train pyreader queue size: 50, learning rate: 0.000003\n",
            "[INFO] 2019-12-29 21:32:55,029 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000003\n",
            "2019-12-29 21:32:55,029-INFO: epoch: 3, progress: 5536/11916, step: 1240, ave loss: 0.107425, ave acc: 0.968750, speed: 3.240256 steps/s\n",
            "[INFO] 2019-12-29 21:32:55,029 [run_classifier.py:  287]:\tepoch: 3, progress: 5536/11916, step: 1240, ave loss: 0.107425, ave acc: 0.968750, speed: 3.240256 steps/s\n",
            "2019-12-29 21:32:58,070-INFO: train pyreader queue size: 50, learning rate: 0.000003\n",
            "[INFO] 2019-12-29 21:32:58,070 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000003\n",
            "2019-12-29 21:32:58,070-INFO: epoch: 3, progress: 5856/11916, step: 1250, ave loss: 0.156115, ave acc: 0.937500, speed: 3.288604 steps/s\n",
            "[INFO] 2019-12-29 21:32:58,070 [run_classifier.py:  287]:\tepoch: 3, progress: 5856/11916, step: 1250, ave loss: 0.156115, ave acc: 0.937500, speed: 3.288604 steps/s\n",
            "2019-12-29 21:33:01,425-INFO: train pyreader queue size: 50, learning rate: 0.000003\n",
            "[INFO] 2019-12-29 21:33:01,425 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000003\n",
            "2019-12-29 21:33:01,425-INFO: epoch: 3, progress: 6176/11916, step: 1260, ave loss: 0.124913, ave acc: 0.968750, speed: 2.980547 steps/s\n",
            "[INFO] 2019-12-29 21:33:01,425 [run_classifier.py:  287]:\tepoch: 3, progress: 6176/11916, step: 1260, ave loss: 0.124913, ave acc: 0.968750, speed: 2.980547 steps/s\n",
            "2019-12-29 21:33:04,521-INFO: train pyreader queue size: 50, learning rate: 0.000003\n",
            "[INFO] 2019-12-29 21:33:04,521 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000003\n",
            "2019-12-29 21:33:04,521-INFO: epoch: 3, progress: 6496/11916, step: 1270, ave loss: 0.061818, ave acc: 1.000000, speed: 3.230318 steps/s\n",
            "[INFO] 2019-12-29 21:33:04,521 [run_classifier.py:  287]:\tepoch: 3, progress: 6496/11916, step: 1270, ave loss: 0.061818, ave acc: 1.000000, speed: 3.230318 steps/s\n",
            "2019-12-29 21:33:07,390-INFO: train pyreader queue size: 50, learning rate: 0.000003\n",
            "[INFO] 2019-12-29 21:33:07,390 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000003\n",
            "2019-12-29 21:33:07,390-INFO: epoch: 3, progress: 6816/11916, step: 1280, ave loss: 0.510083, ave acc: 0.812500, speed: 3.485043 steps/s\n",
            "[INFO] 2019-12-29 21:33:07,390 [run_classifier.py:  287]:\tepoch: 3, progress: 6816/11916, step: 1280, ave loss: 0.510083, ave acc: 0.812500, speed: 3.485043 steps/s\n",
            "2019-12-29 21:33:10,766-INFO: train pyreader queue size: 50, learning rate: 0.000003\n",
            "[INFO] 2019-12-29 21:33:10,766 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000003\n",
            "2019-12-29 21:33:10,767-INFO: epoch: 3, progress: 7136/11916, step: 1290, ave loss: 0.206989, ave acc: 0.937500, speed: 2.961910 steps/s\n",
            "[INFO] 2019-12-29 21:33:10,767 [run_classifier.py:  287]:\tepoch: 3, progress: 7136/11916, step: 1290, ave loss: 0.206989, ave acc: 0.937500, speed: 2.961910 steps/s\n",
            "2019-12-29 21:33:13,931-INFO: train pyreader queue size: 50, learning rate: 0.000003\n",
            "[INFO] 2019-12-29 21:33:13,931 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000003\n",
            "2019-12-29 21:33:13,931-INFO: epoch: 3, progress: 7456/11916, step: 1300, ave loss: 0.294824, ave acc: 0.906250, speed: 3.160376 steps/s\n",
            "[INFO] 2019-12-29 21:33:13,931 [run_classifier.py:  287]:\tepoch: 3, progress: 7456/11916, step: 1300, ave loss: 0.294824, ave acc: 0.906250, speed: 3.160376 steps/s\n",
            "2019-12-29 21:33:16,863-INFO: train pyreader queue size: 50, learning rate: 0.000002\n",
            "[INFO] 2019-12-29 21:33:16,863 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000002\n",
            "2019-12-29 21:33:16,863-INFO: epoch: 3, progress: 7776/11916, step: 1310, ave loss: 0.107412, ave acc: 0.937500, speed: 3.410197 steps/s\n",
            "[INFO] 2019-12-29 21:33:16,863 [run_classifier.py:  287]:\tepoch: 3, progress: 7776/11916, step: 1310, ave loss: 0.107412, ave acc: 0.937500, speed: 3.410197 steps/s\n",
            "2019-12-29 21:33:19,733-INFO: train pyreader queue size: 50, learning rate: 0.000002\n",
            "[INFO] 2019-12-29 21:33:19,733 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000002\n",
            "2019-12-29 21:33:19,733-INFO: epoch: 3, progress: 8096/11916, step: 1320, ave loss: 0.068128, ave acc: 1.000000, speed: 3.484643 steps/s\n",
            "[INFO] 2019-12-29 21:33:19,733 [run_classifier.py:  287]:\tepoch: 3, progress: 8096/11916, step: 1320, ave loss: 0.068128, ave acc: 1.000000, speed: 3.484643 steps/s\n",
            "2019-12-29 21:33:22,568-INFO: train pyreader queue size: 50, learning rate: 0.000002\n",
            "[INFO] 2019-12-29 21:33:22,568 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000002\n",
            "2019-12-29 21:33:22,568-INFO: epoch: 3, progress: 8416/11916, step: 1330, ave loss: 0.240412, ave acc: 0.906250, speed: 3.527461 steps/s\n",
            "[INFO] 2019-12-29 21:33:22,568 [run_classifier.py:  287]:\tepoch: 3, progress: 8416/11916, step: 1330, ave loss: 0.240412, ave acc: 0.906250, speed: 3.527461 steps/s\n",
            "2019-12-29 21:33:25,651-INFO: train pyreader queue size: 50, learning rate: 0.000002\n",
            "[INFO] 2019-12-29 21:33:25,651 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000002\n",
            "2019-12-29 21:33:25,651-INFO: epoch: 3, progress: 8736/11916, step: 1340, ave loss: 0.243731, ave acc: 0.906250, speed: 3.243982 steps/s\n",
            "[INFO] 2019-12-29 21:33:25,651 [run_classifier.py:  287]:\tepoch: 3, progress: 8736/11916, step: 1340, ave loss: 0.243731, ave acc: 0.906250, speed: 3.243982 steps/s\n",
            "2019-12-29 21:33:28,749-INFO: train pyreader queue size: 50, learning rate: 0.000002\n",
            "[INFO] 2019-12-29 21:33:28,749 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000002\n",
            "2019-12-29 21:33:28,749-INFO: epoch: 3, progress: 9056/11916, step: 1350, ave loss: 0.244004, ave acc: 0.937500, speed: 3.228021 steps/s\n",
            "[INFO] 2019-12-29 21:33:28,749 [run_classifier.py:  287]:\tepoch: 3, progress: 9056/11916, step: 1350, ave loss: 0.244004, ave acc: 0.937500, speed: 3.228021 steps/s\n",
            "2019-12-29 21:33:31,951-INFO: train pyreader queue size: 50, learning rate: 0.000002\n",
            "[INFO] 2019-12-29 21:33:31,951 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000002\n",
            "2019-12-29 21:33:31,951-INFO: epoch: 3, progress: 9376/11916, step: 1360, ave loss: 0.053796, ave acc: 1.000000, speed: 3.123466 steps/s\n",
            "[INFO] 2019-12-29 21:33:31,951 [run_classifier.py:  287]:\tepoch: 3, progress: 9376/11916, step: 1360, ave loss: 0.053796, ave acc: 1.000000, speed: 3.123466 steps/s\n",
            "2019-12-29 21:33:34,711-INFO: train pyreader queue size: 50, learning rate: 0.000002\n",
            "[INFO] 2019-12-29 21:33:34,711 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000002\n",
            "2019-12-29 21:33:34,711-INFO: epoch: 3, progress: 9696/11916, step: 1370, ave loss: 0.154391, ave acc: 0.937500, speed: 3.622846 steps/s\n",
            "[INFO] 2019-12-29 21:33:34,711 [run_classifier.py:  287]:\tepoch: 3, progress: 9696/11916, step: 1370, ave loss: 0.154391, ave acc: 0.937500, speed: 3.622846 steps/s\n",
            "2019-12-29 21:33:37,534-INFO: train pyreader queue size: 50, learning rate: 0.000001\n",
            "[INFO] 2019-12-29 21:33:37,534 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000001\n",
            "2019-12-29 21:33:37,534-INFO: epoch: 3, progress: 10016/11916, step: 1380, ave loss: 0.113660, ave acc: 0.968750, speed: 3.542332 steps/s\n",
            "[INFO] 2019-12-29 21:33:37,534 [run_classifier.py:  287]:\tepoch: 3, progress: 10016/11916, step: 1380, ave loss: 0.113660, ave acc: 0.968750, speed: 3.542332 steps/s\n",
            "2019-12-29 21:33:41,061-INFO: train pyreader queue size: 50, learning rate: 0.000001\n",
            "[INFO] 2019-12-29 21:33:41,061 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000001\n",
            "2019-12-29 21:33:41,061-INFO: epoch: 3, progress: 10336/11916, step: 1390, ave loss: 0.202285, ave acc: 0.875000, speed: 2.835662 steps/s\n",
            "[INFO] 2019-12-29 21:33:41,061 [run_classifier.py:  287]:\tepoch: 3, progress: 10336/11916, step: 1390, ave loss: 0.202285, ave acc: 0.875000, speed: 2.835662 steps/s\n",
            "2019-12-29 21:33:44,364-INFO: train pyreader queue size: 50, learning rate: 0.000001\n",
            "[INFO] 2019-12-29 21:33:44,364 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000001\n",
            "2019-12-29 21:33:44,364-INFO: epoch: 3, progress: 10656/11916, step: 1400, ave loss: 0.240581, ave acc: 0.906250, speed: 3.027303 steps/s\n",
            "[INFO] 2019-12-29 21:33:44,364 [run_classifier.py:  287]:\tepoch: 3, progress: 10656/11916, step: 1400, ave loss: 0.240581, ave acc: 0.906250, speed: 3.027303 steps/s\n",
            "2019-12-29 21:33:47,507-INFO: train pyreader queue size: 50, learning rate: 0.000001\n",
            "[INFO] 2019-12-29 21:33:47,507 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000001\n",
            "2019-12-29 21:33:47,507-INFO: epoch: 3, progress: 10976/11916, step: 1410, ave loss: 0.287458, ave acc: 0.906250, speed: 3.181797 steps/s\n",
            "[INFO] 2019-12-29 21:33:47,507 [run_classifier.py:  287]:\tepoch: 3, progress: 10976/11916, step: 1410, ave loss: 0.287458, ave acc: 0.906250, speed: 3.181797 steps/s\n",
            "2019-12-29 21:33:50,396-INFO: train pyreader queue size: 50, learning rate: 0.000001\n",
            "[INFO] 2019-12-29 21:33:50,396 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000001\n",
            "2019-12-29 21:33:50,397-INFO: epoch: 3, progress: 11296/11916, step: 1420, ave loss: 0.131975, ave acc: 0.968750, speed: 3.461326 steps/s\n",
            "[INFO] 2019-12-29 21:33:50,397 [run_classifier.py:  287]:\tepoch: 3, progress: 11296/11916, step: 1420, ave loss: 0.131975, ave acc: 0.968750, speed: 3.461326 steps/s\n",
            "2019-12-29 21:33:53,374-INFO: train pyreader queue size: 50, learning rate: 0.000001\n",
            "[INFO] 2019-12-29 21:33:53,374 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000001\n",
            "2019-12-29 21:33:53,374-INFO: epoch: 3, progress: 11616/11916, step: 1430, ave loss: 0.225017, ave acc: 0.937500, speed: 3.358459 steps/s\n",
            "[INFO] 2019-12-29 21:33:53,374 [run_classifier.py:  287]:\tepoch: 3, progress: 11616/11916, step: 1430, ave loss: 0.225017, ave acc: 0.937500, speed: 3.358459 steps/s\n",
            "2019-12-29 21:33:56,233-INFO: train pyreader queue size: 50, learning rate: 0.000001\n",
            "[INFO] 2019-12-29 21:33:56,233 [run_classifier.py:  275]:\ttrain pyreader queue size: 50, learning rate: 0.000001\n",
            "2019-12-29 21:33:56,233-INFO: epoch: 3, progress: 11915/11916, step: 1440, ave loss: 0.219167, ave acc: 0.875000, speed: 3.498053 steps/s\n",
            "[INFO] 2019-12-29 21:33:56,233 [run_classifier.py:  287]:\tepoch: 3, progress: 11915/11916, step: 1440, ave loss: 0.219167, ave acc: 0.875000, speed: 3.498053 steps/s\n",
            "2019-12-29 21:33:59,176-INFO: train pyreader queue size: 41, learning rate: 0.000001\n",
            "[INFO] 2019-12-29 21:33:59,176 [run_classifier.py:  275]:\ttrain pyreader queue size: 41, learning rate: 0.000001\n",
            "2019-12-29 21:33:59,176-INFO: epoch: 3, progress: 11915/11916, step: 1450, ave loss: 0.213137, ave acc: 0.968750, speed: 3.398147 steps/s\n",
            "[INFO] 2019-12-29 21:33:59,176 [run_classifier.py:  287]:\tepoch: 3, progress: 11915/11916, step: 1450, ave loss: 0.213137, ave acc: 0.968750, speed: 3.398147 steps/s\n",
            "2019-12-29 21:34:01,893-INFO: train pyreader queue size: 31, learning rate: 0.000000\n",
            "[INFO] 2019-12-29 21:34:01,893 [run_classifier.py:  275]:\ttrain pyreader queue size: 31, learning rate: 0.000000\n",
            "2019-12-29 21:34:01,893-INFO: epoch: 3, progress: 11915/11916, step: 1460, ave loss: 0.428363, ave acc: 0.875000, speed: 3.681052 steps/s\n",
            "[INFO] 2019-12-29 21:34:01,893 [run_classifier.py:  287]:\tepoch: 3, progress: 11915/11916, step: 1460, ave loss: 0.428363, ave acc: 0.875000, speed: 3.681052 steps/s\n",
            "2019-12-29 21:34:05,196-INFO: train pyreader queue size: 21, learning rate: 0.000000\n",
            "[INFO] 2019-12-29 21:34:05,196 [run_classifier.py:  275]:\ttrain pyreader queue size: 21, learning rate: 0.000000\n",
            "2019-12-29 21:34:05,197-INFO: epoch: 3, progress: 11915/11916, step: 1470, ave loss: 0.180473, ave acc: 0.937500, speed: 3.026702 steps/s\n",
            "[INFO] 2019-12-29 21:34:05,197 [run_classifier.py:  287]:\tepoch: 3, progress: 11915/11916, step: 1470, ave loss: 0.180473, ave acc: 0.937500, speed: 3.026702 steps/s\n",
            "2019-12-29 21:34:08,222-INFO: train pyreader queue size: 11, learning rate: 0.000000\n",
            "[INFO] 2019-12-29 21:34:08,222 [run_classifier.py:  275]:\ttrain pyreader queue size: 11, learning rate: 0.000000\n",
            "2019-12-29 21:34:08,223-INFO: epoch: 3, progress: 11915/11916, step: 1480, ave loss: 0.135617, ave acc: 0.968750, speed: 3.304963 steps/s\n",
            "[INFO] 2019-12-29 21:34:08,223 [run_classifier.py:  287]:\tepoch: 3, progress: 11915/11916, step: 1480, ave loss: 0.135617, ave acc: 0.968750, speed: 3.304963 steps/s\n",
            "2019-12-29 21:34:11,086-INFO: train pyreader queue size: 1, learning rate: 0.000000\n",
            "[INFO] 2019-12-29 21:34:11,086 [run_classifier.py:  275]:\ttrain pyreader queue size: 1, learning rate: 0.000000\n",
            "2019-12-29 21:34:11,086-INFO: epoch: 3, progress: 11915/11916, step: 1490, ave loss: 0.162741, ave acc: 0.937500, speed: 3.492250 steps/s\n",
            "[INFO] 2019-12-29 21:34:11,086 [run_classifier.py:  287]:\tepoch: 3, progress: 11915/11916, step: 1490, ave loss: 0.162741, ave acc: 0.937500, speed: 3.492250 steps/s\n",
            "2019-12-29 21:34:16,153-INFO: testing dataset/sem-eval/val.tsv, save to output/test_out.{1..5}.2e-5.32.4.tsv.3.1493\n",
            "[INFO] 2019-12-29 21:34:16,153 [run_classifier.py:  421]:\ttesting dataset/sem-eval/val.tsv, save to output/test_out.{1..5}.2e-5.32.4.tsv.3.1493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikh7W7nnl-sf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"output/test_out.{1..5}.2e-5.32.4.tsv.3.1493\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJgE_vI_nJ73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_out = pd.read_csv(\"output/test_out.{1..5}.2e-5.32.4.tsv.3.1493\", delimiter='\\t', header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU_aQGA4pQRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "pattern = re.compile(r'(,){2,}')\n",
        "\n",
        "def parse_element(el):\n",
        "  multiple_commas = el.replace(' ', ',')[1:-1]\n",
        "  one_comma = re.sub(pattern, ',', multiple_commas)\n",
        "  return float(one_comma.split(',')[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYIIFETDnis5",
        "colab_type": "code",
        "outputId": "0a0bf807-9943-42b5-8d3b-f78b2b4110b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "preds = [parse_element(el) for el in test_out[1]]\n",
        "preds[:20]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.87108123,\n",
              " 0.952258,\n",
              " 0.96701026,\n",
              " 0.97473025,\n",
              " 0.95807177,\n",
              " 0.00673935,\n",
              " 0.7690937,\n",
              " 0.01468256,\n",
              " 0.01104505,\n",
              " 0.97675025,\n",
              " 0.02298346,\n",
              " 0.47771004,\n",
              " 0.5081026,\n",
              " 0.01658216,\n",
              " 0.01078551,\n",
              " 0.96044254,\n",
              " 0.80696654,\n",
              " 0.7182258,\n",
              " 0.01436398,\n",
              " 0.08695079]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5uq7K-qnpR4",
        "colab_type": "code",
        "outputId": "80aac14f-d1ca-48e6-fa4a-d803074cbbb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "validation_y\n",
        "float_validation_y = [float(el) for el in validation_y]\n",
        "float_validation_y[:20]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XzVUD15tOYf",
        "colab_type": "code",
        "outputId": "8bdd2ee1-3440-40a2-ca8e-9006de79a17c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.metrics import binary_accuracy\n",
        "acc = binary_accuracy(float_validation_y, preds)\n",
        "with tf.Session() as sess:\n",
        "  print(acc.eval()) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8066465\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP-0DBiYu7eH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN76HnNVu9DD",
        "colab_type": "code",
        "outputId": "ca04563c-d1d5-41a8-d6b4-2a7afec3b50d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f1_val = f1(tf.cast(validation_y, tf.float32), preds)\n",
        "with tf.Session() as sess:\n",
        "  print(f1_val.eval()) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7104072\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}